[{"id":0,"href":"/posts/2024/12/mac%E4%B8%ADvscode%E6%89%93%E5%BC%80devdocker%E6%8F%90%E7%A4%BAremote-extension-host-terminated-unexpectedly/","title":"mac中vscode打开devdocker提示\"Remote Extension host terminated unexpectedly\"","section":"Blog","content":" 参考 # https://github.com/microsoft/vscode-remote-release/issues/8967#issuecomment-1873199481\nswitched from VirtioFS to gRPC FUSE and disabled \u0026lsquo;Use Virtualization Framework\u0026rsquo; in my Docker Desktop settings\n"},{"id":1,"href":"/posts/2024/12/cursor%E4%BF%AEmachine-id/","title":"cursor修machine id","section":"Blog","content":" 手动配置方法 # 完全关闭 Cursor\n找到配置文件位置：\nWindows: %APPDATA%\\Cursor\\User\\globalStorage\\storage.json macOS: ~/Library/Application Support/Cursor/User/globalStorage/storage.json Linux: ~/.config/Cursor/User/globalStorage/storage.json 备份 storage.json\n编辑 storage.json 并更新以下字段（使用新的随机UUID）：\n{ \u0026#34;telemetry.machineId\u0026#34;: \u0026#34;生成新的uuid\u0026#34;, \u0026#34;telemetry.macMachineId\u0026#34;: \u0026#34;生成新的uuid\u0026#34;, \u0026#34;telemetry.devDeviceId\u0026#34;: \u0026#34;生成新的uuid\u0026#34;, \u0026#34;telemetry.sqmId\u0026#34;: \u0026#34;生成新的uuid\u0026#34;, \u0026#34;lastModified\u0026#34;: \u0026#34;2024-01-01T00:00:00.000Z\u0026#34;, \u0026#34;version\u0026#34;: \u0026#34;1.0.1\u0026#34; } 保存文件并重启 Cursor "},{"id":2,"href":"/posts/2024/12/swiftui%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/","title":"swiftui学习笔记","section":"Blog","content":" SwiftUI学习笔记 # Concept # Scene # 程序的入口 # @main来标识 必须有且只有一个，body 是必须的， 返回一个Scene\n@main struct MyApp: App { var body: some Scene { WindowGroup { ContentView() } } } Scene\nWindowGroup: 是 Scene 的子类， 表示一个窗口组， 可以包含多个窗口 Window: 表示一个窗口， 可以包含多个视图 Document Group: 表示一个文档组， 可以包含多个文档 Settings: 表示一个设置组， 可以包含多个设置 View # 视图是什么？\n视图是 SwiftUI 中的基本构建块， 用于构建用户界面 视图可以包含其他视图， 形成层次结构 视图可以包含数据和行为， 用于构建动态和交互式的用户界面 视图可以包含样式和布局， 用于构建美观和一致的用户界面 "},{"id":3,"href":"/posts/2024/10/spark-mongodb/","title":"spark \u0026 mongodb","section":"Blog","content":" spark # https://spark.apache.org/docs/latest/api/python/index.html#index-page-spark-sql-and-dataframes\nSpark SQL \u0026amp; DataFrames spark.createDataFrame df.show() df.columns df.printSchema() Pandas API on Spark Structured Streaming Machine Learning mongodb # 安装 # https://www.mongodb.com/zh-cn/docs/v6.0/tutorial/install-mongodb-on-os-x/\n启停服务 # brew services stop mongodb-community@7.0 配置文件 # https://www.mongodb.com/zh-cn/docs/v6.0/reference/configuration-options/\ndebug # 要验证 MongoDB 是否正在运行，请执行以下操作之一：\n如果将 MongoDB 作为 macOS 服务启动： brew services list 应该会看到服务 mongodb-community 列为 started。\n如果将 MongoDB 作为后台进程手动启动： ps aux | grep -v grep | grep mongod 应该在输出中看到 mongod 进程。\n还可以查看日志文件，看到 mongod 进程的当前状态：/usr/local/var/log/mongodb/mongo.log。\n"},{"id":4,"href":"/posts/2024/10/jemalloc%E5%88%86%E6%9E%90/","title":"jemalloc分析","section":"Blog","content":" jemalloc 源码分析 # https://blog.lfalive.top/2022/02/15/JeMalloc/ https://uncp.github.io/JeMalloc/ https://blog.csdn.net/qq_37517281/article/details/132760960 jemalloc heap profile # jemalloc statistic # 配置方法 # 通过MALLOC_CONF环境变量使能\nexport MALLOC_CONF=stats_interval:256000000\nopt.stats_interval (int64_t) r-\nAverage interval between statistics outputs, as measured in bytes of allocation activity. The actual interval may be sporadic because decentralized event counters are used to avoid synchronization bottlenecks. The output may be triggered on any thread, which then calls malloc_stats_print(). opt.stats_interval_opts can be combined to specify output options. By default, interval-triggered stats output is disabled (encoded as -1).\nopt.stats_interval_opts (const char *) r-\nOptions (the opts string) to pass to the malloc_stats_print() for interval based statistics printing (enabled through opt.stats_interval). See available options in malloc_stats_print(). Has no effect unless opt.stats_interval is enabled. The default is “”.\nstats_interval_opts配置选项 opts 作用 J presented in JSON format g omit general information that never changes during execution m omit merged arena statistics d omit destroyed merged arena statistics a omit per arena statistics b omit per size class statistics for bins l omit per size class statistics for large objects x omit all mutex statistics e omit extent statistics 统计数据 # 配置信息 # general information that never changes during execution\n一般来说是不变的。打开g选项可以屏蔽。\nVersion: \u0026#34;0.0.0-0-g000000missing_version_try_git_fetch_tags\u0026#34; Build-time option settings config.cache_oblivious: true config.debug: false config.fill: true config.lazy_lock: false config.malloc_conf: \u0026#34;\u0026#34; config.opt_safety_checks: false config.prof: true config.prof_libgcc: true config.prof_libunwind: false config.stats: true config.utrace: false config.xmalloc: false Run-time option settings opt.abort: false opt.abort_conf: false opt.cache_oblivious: true opt.confirm_conf: false opt.retain: true opt.dss: \u0026#34;secondary\u0026#34; opt.narenas: 12 opt.percpu_arena: \u0026#34;disabled\u0026#34; opt.oversize_threshold: 8388608 opt.hpa: false opt.hpa_slab_max_alloc: 65536 opt.hpa_hugification_threshold: 1992294 opt.hpa_hugify_delay_ms: 10000 opt.hpa_min_purge_interval_ms: 5000 opt.hpa_dirty_mult: \u0026#34;0.25\u0026#34; opt.hpa_sec_nshards: 4 opt.hpa_sec_max_alloc: 32768 opt.hpa_sec_max_bytes: 262144 opt.hpa_sec_bytes_after_flush: 131072 opt.hpa_sec_batch_fill_extra: 0 opt.metadata_thp: \u0026#34;auto\u0026#34; opt.mutex_max_spin: 600 opt.background_thread: false (background_thread: false) opt.dirty_decay_ms: 20000 (arenas.dirty_decay_ms: 20000) opt.muzzy_decay_ms: 20000 (arenas.muzzy_decay_ms: 20000) opt.lg_extent_max_active_fit: 6 opt.junk: \u0026#34;false\u0026#34; opt.zero: false opt.experimental_infallible_new: false opt.tcache: true opt.tcache_max: 32768 opt.tcache_nslots_small_min: 20 opt.tcache_nslots_small_max: 200 opt.tcache_nslots_large: 20 opt.lg_tcache_nslots_mul: 1 opt.tcache_gc_incr_bytes: 65536 opt.tcache_gc_delay_bytes: 0 opt.lg_tcache_flush_small_div: 1 opt.lg_tcache_flush_large_div: 1 opt.thp: \u0026#34;default\u0026#34; opt.prof: false opt.prof_prefix: \u0026#34;jeprof\u0026#34; opt.prof_active: true (prof.active: false) opt.prof_thread_active_init: true (prof.thread_active_init: false) opt.lg_prof_sample: 19 (prof.lg_sample: 0) opt.prof_accum: false opt.lg_prof_interval: -1 opt.prof_gdump: false opt.prof_final: false opt.prof_leak: false opt.prof_leak_error: false opt.stats_print: false opt.stats_print_opts: \u0026#34;Jg\u0026#34; opt.stats_print: false opt.stats_print_opts: \u0026#34;Jg\u0026#34; opt.stats_interval: 256000000 opt.stats_interval_opts: \u0026#34;\u0026#34; opt.zero_realloc: \u0026#34;free\u0026#34; Profiling settings prof.thread_active_init: false prof.active: false prof.gdump: false prof.interval: 0 prof.lg_sample: 0 Arenas: 13 Quantum size: 16 Page size: 4096 Maximum thread-cached size class: 32768 Number of bin size classes: 36 Number of thread-cache bin size classes: 41 Number of large size classes: 196 整体情况 # Allocated: 13228376, active: 14700544, metadata: 6435696 (n_thp 0), resident: 23420928, mapped: 53010432, retained: 22487040 Count of realloc(non-null-ptr, 0) calls: 0 Background threads: 0, num_runs: 0, run_interval: 0 ns 字段 含义 备注 Allocated Total number of bytes allocated by the application.]() 应用分配的字节数 active Total number of bytes in active pages allocated by the application.This is a multiple of the page size, and greater than or equal to stats.allocated. This does not include stats.arenas.\u0026lt;i\u0026gt;.pdirty, stats.arenas.\u0026lt;i\u0026gt;.pmuzzy, nor pages entirely devoted to allocator metadata. metadata Total number of bytes dedicated to metadata,which comprise base allocations used for bootstrap-sensitive allocator metadata structures (see stats.arenas.\u0026lt;i\u0026gt;.base) and internal allocations (see stats.arenas.\u0026lt;i\u0026gt;.internal). Transparent huge page (enabled with opt.metadata_thp) usage is not considered. metadata占用的字节数 metadata_thp Number of transparent huge pages (THP) used for metadata.See stats.metadata and opt.metadata_thp) for details. resident Maximum number of bytes in physically resident data pages mapped by the allocator,comprising all pages dedicated to allocator metadata, pages backing active allocations, and unused dirty pages. This is a maximum rather than precise because pages may not actually be physically resident if they correspond to demand-zeroed virtual memory that has not yet been touched. This is a multiple of the page size, and is larger than stats.active. 物理驻留内存 mapped Total number of bytes in active extents mapped by the allocator.This is larger than stats.active. This does not include inactive extents, even those that contain unused dirty pages, which means that there is no strict ordering between this and stats.resident. reatained Total number of bytes in virtual memory mappings that were retained rather than being returned to the operating system via e.g. munmap(2) or similar. Retained virtual memory is typically untouched, decommitted, or purged, so it has no strongly associated physical memory (see extent hooks for details). Retained memory is excluded from mapped memory statistics, e.g. stats.mapped. 未被使用但仍保留的字节数 zero_reallocs Number of times that the realloc() was called with a non-NULL pointer argument and a 0 size argument. This is a fundamentally unsafe pattern in portable programs; see opt.zero_realloc for details. background_thread.num_threads Number of background threads running currently. background_thread.num_runs Total number of runs from all background threads. background_thread.run_interval Average run interval in nanoseconds of background threads. mutex相关统计 # n_lock_ops (#/sec) n_waiting (#/sec) n_spin_acq (#/sec) n_owner_switch (#/sec) total_wait_ns (#/sec) max_wait_ns max_n_thds background_thread 689 0 0 0 0 0 12 0 0 0 0 0 max_per_bg_thd 0 0 0 0 0 0 0 0 0 0 0 0 ctl 16288313 15053 0 0 0 0 1 0 0 0 0 0 prof 0 0 0 0 0 0 0 0 0 0 0 0 prof_thds_data 0 0 0 0 0 0 0 0 0 0 0 0 prof_dump 0 0 0 0 0 0 0 0 0 0 0 0 prof_recent_alloc 0 0 0 0 0 0 0 0 0 0 0 0 prof_recent_dump 0 0 0 0 0 0 0 0 0 0 0 0 prof_stats 0 0 0 0 0 0 0 0 0 0 0 0 stats.mutexes.ctl.{counter}\n列 # Statistics on ctl mutex (global scope; mallctl related). {counter} is one of the counters below:\n指标 含义 备注 num_ops Total number of lock acquisition operations on this mutex. num_spin_acq Number of times the mutex was spin-acquired.When the mutex is currently locked and cannot be acquired immediately,a short period of spin-retry within jemalloc will be performed. Acquired through spin generally means the contention was lightweight and not causing context switches. spin等mutex的次数 num_wait Number of times the mutex was wait-acquired,which means the mutex contention was not solved by spin-retry, and blocking operation was likely involved in order to acquire the mutex.This event generally implies higher cost / longer delay, and should be investigated if it happens often. wait等mutex的次数 max_wait_time Maximum length of time in nanoseconds spent on a single wait-acquired lock operation.Note that to avoid profiling overhead on the common path, this does not consider spin-acquired cases. 最长 wait等 时间 total_wait_time Cumulative time in nanoseconds spent on wait-acquired lock operations. Similarly, spin-acquired cases are not considered. 累计 wait等 时间 max_num_thds Maximum number of threads waiting on this mutex simultaneously. Similarly, spin-acquired cases are not considered. 最多同时等这个mutex的线程数 num_owner_switch Number of times the current mutex owner is different from the previous one.This event does not generally imply an issue; rather it is an indicator of how often the protected data are accessed by different threads. mutex owner切换的次数 行 # 不同的mutex\nmutex 作用 备注 background_thread prof prof_thds_data prof threads data mutex prof_dump prof dumping mutex 另外几个文档里没写\narena statistics # 分为merged arena和各个arena；具体的内容是相同的；merged是其他的加总。\n整体 # threads, uptime, dss # Merged arenas stats: assigned threads: 12 uptime: 1082888000000 dss allocation precedence: \u0026#34;N/A\u0026#34; assigned threads：线程数 uptime：arena创建后的时间，ns dss allocation precedence: 使用sbrk接口申请内存的优先权。一般更推荐用mmap。 dirty \u0026amp; muzzy decay # decaying: time npages sweeps madvises purged dirty: N/A 649 725 1238 13926 muzzy: N/A 0 382 667 4219 内存释放： dirty -(madvise(\u0026hellip;, MADV_FREE))-\u0026gt; muzzy -(madvise(\u0026hellip;, MADV_DONTNEED))-\u0026gt; clean 详见：https://github.com/jemalloc/jemalloc/issues/521 参数 含义 备注 dirty_npurge Number of dirty page purge sweeps performed. dirty_nmadvise Number of madvise() or similar calls made to purge dirty pages. dirty_purged Number of dirty pages purged. muzzy_npurge Number of muzzy page purge sweeps performed. muzzy_nmadvise Number of madvise() or similar calls made to purge muzzy pages. muzzy_purged Number of muzzy pages purged. small \u0026amp; large \u0026amp; total # allocated nmalloc (#/sec) ndalloc (#/sec) nrequests (#/sec) nfill (#/sec) nflush (#/sec) small: 7117144 592932 547 555690 513 76036438 70273 286490 264 110463 102 large: 6111232 868287 802 868205 802 868323 802 868287 802 27 0 total: 13228376 1461219 1350 1423895 1315 76904761 71076 1154777 1067 110490 102 small 参数 含义 备注 small.allocated Number of bytes currently allocated by small objects. 当前分配的字节数 small.nmalloc Cumulative number of times a small allocation was requested from the arena\u0026rsquo;s bins,whether to fill the relevant tcache if opt.tcache is enabled, or to directly satisfy an allocation request otherwise. 累计分配次数 small.ndalloc Cumulative number of times a small allocation was returned to the arena\u0026rsquo;s bins,whether to flush the relevant tcache if opt.tcache is enabled, or to directly deallocate an allocation otherwise. 累计释放次数 small.nrequests Cumulative number of allocation requests satisfied by all bin size classes. 累计bin满足分配的次数 small.nfills Cumulative number of tcache fills by all small size classes. 累计tcache fill次数 small.nflushes Cumulative number of tcache flushes by all small size classes. 累计tcache flush次数 large 参数 含义 备注 large.allocated Number of bytes currently allocated by large objects. large.nmalloc Cumulative number of times a large extent was allocated from the arena,whether to fill the relevant tcache if opt.tcache is enabled and the size class is within the range being cached, or to directly satisfy an allocation request otherwise. large.ndalloc Cumulative number of times a large extent was returned to the arena,whether to flush the relevant tcache if opt.tcache is enabled and the size class is within the range being cached, or to directly deallocate an allocation otherwise. large.nrequests Cumulative number of allocation requests satisfied by all large size classes. large.nfills Cumulative number of tcache fills by all large size classes. large.nflushes Cumulative number of tcache flushes by all large size classes. 其他信息 # mapped: 53010432 retained: 22487040 base: 6026096 internal: 409600 metadata_thp: 0 tcache_bytes: 1893992 tcache_stashed_bytes: 0 resident: 23420928 abandoned_vm: 0 extent_avail: 62 参数 含义 备注 mapped Number of mapped bytes. retained Number of retained bytes. See stats.retained for details. base Number of bytes dedicated to bootstrap-sensitive allocator metadata structures. internal Number of bytes dedicated to internal allocations. Internal allocations differ from application-originated allocations in that they are for internal use, and that they are omitted from heap profiles. metadata_thp Number of transparent huge pages (THP) used for metadata. See opt.metadata_thp for details. resident Maximum number of bytes in physically resident data pages mapped by the arena,comprising all pages dedicated to allocator metadata, pages backing active allocations, and unused dirty pages. This is a maximum rather than precise because pages may not actually be physically resident if they correspond to demand-zeroed virtual memory that has not yet been touched. This is a multiple of the page size. extent_avail Number of allocated (but unused) extent structs in this arena. stats.arenas.\u0026lt;i\u0026gt;.pactive (size_t) r-Number of pages in active extents.\nstats.arenas.\u0026lt;i\u0026gt;.pdirty (size_t) r-Number of pages within unused extents that are potentially dirty, and for which madvise() or similar has not been called. See opt.dirty_decay_ms for a description of dirty pages.\nstats.arenas.\u0026lt;i\u0026gt;.pmuzzy (size_t) r-Number of pages within unused extents that are muzzy. See opt.muzzy_decay_ms for a description of muzzy pages.\nmutex的情况 # n_lock_ops (#/sec) n_waiting (#/sec) n_spin_acq (#/sec) n_owner_switch (#/sec) total_wait_ns (#/sec) max_wait_ns max_n_thds large 2676 2 0 0 0 0 12 0 0 0 0 0 extent_avail 1408609 1301 0 0 0 0 294 0 0 0 0 0 extents_dirty 1769484 1635 0 0 5 0 1385 1 0 0 0 0 extents_muzzy 6840 6 0 0 0 0 66 0 0 0 0 0 extents_retained 4525 4 0 0 0 0 54 0 0 0 0 0 decay_dirty 6117 5 0 0 0 0 206 0 0 0 0 0 decay_muzzy 5774 5 0 0 0 0 206 0 0 0 0 0 base 6408 5 0 0 0 0 45 0 0 0 0 0 tcache_list 2690 2 0 0 0 0 24 0 0 0 0 0 hpa_shard 0 0 0 0 0 0 0 0 0 0 0 0 hpa_shard_grow 0 0 0 0 0 0 0 0 0 0 0 0 hpa_sec 0 0 0 0 0 0 0 0 0 0 0 0 bins # bins: size ind allocated nmalloc (#/sec) ndalloc (#/sec) nrequests (#/sec) nshards curregs curslabs nonfull_slabs regs pgs util nfills (#/sec) nflushes (#/sec) nslabs nreslabs (#/sec) n_lock_ops (#/sec) n_waiting (#/sec) n_spin_acq (#/sec) n_owner_switch (#/sec) total_wait_ns (#/sec) max_wait_ns max_n_thds 8 0 17512 175799 162 173610 160 12313401 11380 1 2189 9 0 512 1 0.475 158539 146 15842 14 9 18914 17 177067 163 0 0 0 0 44 0 0 0 0 0 16 1 102096 35086 32 28705 26 6984984 6455 1 6381 29 1 256 1 0.859 21296 19 11101 10 29 24794 22 35104 32 0 0 0 0 63 0 0 0 0 0 32 2 334848 45359 41 34895 32 11337157 10477 1 10464 93 16 128 1 0.879 16142 14 13303 12 164 11617 10 32287 29 0 0 0 0 67 0 0 0 0 0 48 3 376608 20279 18 12433 11 1490700 1377 1 7846 37 6 256 3 0.828 1394 1 1087 1 65 352 0 5224 4 0 0 0 0 147 0 0 0 0 0 64 4 426240 16417 15 9757 9 11855396 10956 1 6660 108 4 64 1 0.963 7413 6 5865 5 116 2163 1 16071 14 0 0 0 0 52 0 0 0 0 0 80 5 48720 11422 10 10813 9 187963 173 1 609 8 1 256 5 0.297 8581 7 2233 2 15 5 0 13525 12 0 0 0 0 154 0 0 0 0 0 96 6 23232 9390 8 9148 8 161364 149 1 242 6 1 128 3 0.315 4917 4 4526 4 6 1 0 12126 11 0 0 0 0 35 0 0 0 0 0 112 7 11760 7292 6 7187 6 32461 30 1 105 3 0 256 7 0.136 6783 6 2145 1 1083 0 0 12688 11 0 0 0 0 28 0 0 0 0 0 128 8 19456 2900 2 2748 2 9215219 8516 1 152 8 1 32 1 0.593 1353 1 1298 1 568 1193 1 5969 5 0 0 0 0 395 0 0 0 0 0 160 9 60480 2424 2 2046 1 26904 24 1 378 6 0 128 5 0.492 1245 1 1212 1 6 0 0 5246 4 0 0 0 0 534 0 0 0 0 0 192 10 13056 2259 2 2191 2 35045 32 1 68 3 0 64 3 0.354 1999 1 2011 1 1999 0 0 8686 8 0 0 0 0 48 0 0 0 0 0 224 11 22848 1527 1 1425 1 7140 6 1 102 3 0 128 7 0.265 1101 1 1111 1 20 0 0 4909 4 0 0 0 0 65 0 0 0 0 0 256 12 17152 165 0 98 0 7923492 7323 1 67 6 1 16 1 0.697 32 0 35 0 9 2 0 2753 2 0 0 0 0 26 0 0 0 0 0 320 13 99520 33065 30 32754 30 88019 81 1 311 7 2 64 5 0.694 7715 7 8045 7 102 1007 0 18861 17 0 0 0 0 1138 1 0 0 0 0 384 14 84096 178530 165 178311 164 512638 473 1 219 11 3 32 3 0.622 14274 13 17382 16 1275 11082 10 38734 35 0 0 0 0 3552 3 0 0 0 0 448 15 57792 1785 1 1656 1 6864 6 1 129 3 0 64 7 0.671 1414 1 1121 1 1098 0 0 6310 5 0 0 0 0 55 0 0 0 0 0 512 16 20480 613 0 573 0 6293733 5816 1 40 8 1 8 1 0.625 554 0 554 0 11 2 0 3796 3 0 0 0 0 17 0 0 0 0 0 640 17 51840 21482 19 21401 19 199068 183 1 81 6 0 32 5 0.421 15049 13 4701 4 21 0 0 22449 20 0 0 0 0 60 0 0 0 0 0 768 18 39936 6868 6 6816 6 72130 66 1 52 5 0 16 3 0.650 4042 3 4222 3 14 2069 1 11136 10 0 0 0 0 772 0 0 0 0 0 896 19 28672 1398 1 1366 1 2471 2 1 32 1 0 32 7 1 1227 1 1017 0 990 0 0 5913 5 0 0 0 0 25 0 0 0 0 0 1024 20 57344 5431 5 5375 4 4743775 4384 1 56 17 2 4 1 0.823 1084 1 1373 1 716 2004 1 6143 5 0 0 0 0 953 0 0 0 0 0 1280 21 67840 1560 1 1507 1 3114 2 1 53 5 2 16 5 0.662 1414 1 1172 1 1088 2 0 6351 5 0 0 0 0 27 0 0 0 0 0 1536 22 19968 548 0 535 0 580 0 1 13 4 0 8 3 0.406 474 0 445 0 445 3 0 4041 3 0 0 0 0 20 0 0 0 0 0 1792 23 59136 666 0 633 0 695 0 1 33 3 0 16 7 0.687 582 0 585 0 582 0 0 4426 4 0 0 0 0 18 0 0 0 0 0 2048 24 69632 3086 2 3052 2 1258618 1163 1 34 18 0 2 1 0.944 1956 1 1956 1 1977 1082 1 8566 7 0 0 0 0 17 0 0 0 0 0 2560 25 81920 1153 1 1121 1 1673 1 1 32 7 0 8 5 0.571 1088 1 1089 1 12 3 0 4866 4 0 0 0 0 25 0 0 0 0 0 3072 26 73728 222 0 198 0 138 0 1 24 7 1 4 3 0.857 79 0 80 0 92 4 0 2928 2 0 0 0 0 15 0 0 0 0 0 3584 27 43008 46 0 34 0 11 0 1 12 4 0 8 7 0.375 11 0 13 0 6 2 0 2707 2 0 0 0 0 17 0 0 0 0 0 4096 28 90112 898 0 876 0 1269096 1172 1 22 22 0 1 1 1 861 0 862 0 898 0 0 5298 4 0 0 0 0 17 0 0 0 0 0 5120 29 3758080 3945 3 3211 2 10905 10 1 734 184 1 4 5 0.997 2753 2 2949 2 229 2884 2 8608 7 0 0 0 0 22 0 0 0 0 0 6144 30 61440 30 0 20 0 4 0 1 10 5 0 2 3 1 3 0 5 0 15 2 0 2700 2 0 0 0 0 15 0 0 0 0 0 7168 31 143360 20 0 0 0 0 0 1 20 6 0 4 7 0.833 2 0 1 0 6 0 0 2686 2 0 0 0 0 15 0 0 0 0 0 8192 32 253952 1157 1 1126 1 1606 1 1 31 31 0 1 2 1 1090 1 1092 1 1157 0 0 6016 5 0 0 0 0 21 0 0 0 0 0 10240 33 215040 70 0 49 0 70 0 1 21 12 1 2 5 0.875 19 0 24 0 32 11 0 2752 2 0 0 0 0 23 0 0 0 0 0 12288 34 122880 30 0 20 0 4 0 1 10 10 0 1 3 1 3 0 5 0 30 0 0 2715 2 0 0 0 0 15 0 0 0 0 0 14336 35 143360 10 0 0 0 0 0 1 10 5 0 2 7 1 1 0 1 0 5 0 0 2684 2 0 0 0 0 14 0 0 0 0 0 数据 数据 \u0026hellip; 数据 参数 含义 备注 size 8 16 14336 大小 ind 0 1 35 index allocated 17512 102096 143360 当前分配的字节数 nmalloc (#/sec) 175799 (162) 35086 (32) 10 (0) bins.\u0026lt;j\u0026gt;.nmalloc Cumulative number of times a bin region of the corresponding size class was allocated from the arena,whether to fill the relevant tcache if opt.tcache is enabled, or to directly satisfy an allocation request otherwise. 累计分配个数 ndalloc (#/sec) 173610 (160) 28705 (26) 0 (0) bins.\u0026lt;j\u0026gt;.ndalloc Cumulative number of times a bin region of the corresponding size class was returned to the arena,whether to flush the relevant tcache if opt.tcache is enabled, or to directly deallocate an allocation otherwise. 累计释放个数 nrequests (#/sec) 12313401 (11380) 6984984 (6455) 0 (0) bins.\u0026lt;j\u0026gt;.nrequests Cumulative number of allocation requests satisfied by bin regions of the corresponding size class. nshards 1 1 1 curregs 2189 6381 10 (0) bins.\u0026lt;j\u0026gt;.curregs Current number of regions for this size class. 当前使用个数 curslabs 9 29 5 bins.\u0026lt;j\u0026gt;.curslabs Current number of slabs. 当前slab数 nonfull_slabs 0 1 0 bins.\u0026lt;j\u0026gt;.nonfull_slabs Current number of nonfull slabs. 当前空闲slab数 regs 512 256 2 pgs 1 1 7 util 0.475 0.859 1 nfills (#/sec) 158539 (146) 21296 (19) 1 (0) bins.\u0026lt;j\u0026gt;.nfills Cumulative number of tcache fills. nflushes (#/sec) 15842 (14) 11101 (10) 1 (0) bins.\u0026lt;j\u0026gt;.nflushes Cumulative number of tcache flushes. nslabs 9 29 5 bins.\u0026lt;j\u0026gt;.nslabs Cumulative number of slabs created. nreslabs (#/sec) 18914 (17) 24794 (22) 0 (0) bins.\u0026lt;j\u0026gt;.nreslabs Cumulative number of times the current slab from which to allocate changed. n_lock_ops (#/sec) 177067 (163) 35104 (32) 2684 (2) bins.\u0026lt;j\u0026gt;.mutex.{counter} Statistics on arena.\u0026lt;i\u0026gt;.bins.\u0026lt;j\u0026gt; mutex (arena bin scope; bin operation related). {counter} is one of the counters in mutex profiling counters. n_waiting (#/sec) 0 (0) 0 (0) 0 (0) n_spin_acq (#/sec) 0 (0) 0 (0) 0 (0) n_owner_switch (#/sec) 44 (0) 63 (0) 14 (0) total_wait_ns (#/sec) 0 (0) 0 (0) 0 (0) max_wait_ns 0 0 0 max_n_thds 0 0 0 逐bin的small数据统计，以及bin中mutex的各类操作统计\n有一些数据的含义文档中没写。\nlarge # large: size ind allocated nmalloc (#/sec) ndalloc (#/sec) nrequests (#/sec) curlextents 16384 36 32768 3 0 1 0 3 0 2 20480 37 389120 33 0 14 0 60 0 19 24576 38 0 1 0 1 0 1 0 0 28672 39 430080 17 0 2 0 17 0 15 32768 40 65536 5 0 3 0 14 0 2 40960 41 696320 867943 802 867926 802 867943 802 17 49152 42 49152 2 0 1 0 2 0 1 57344 43 57344 1 0 0 0 1 0 1 65536 44 196608 224 0 221 0 224 0 3 81920 45 983040 29 0 17 0 29 0 12 98304 46 0 1 0 1 0 1 0 0 114688 47 0 8 0 8 0 8 0 0 --- 163840 49 1310720 11 0 3 0 11 0 8 196608 50 0 1 0 1 0 1 0 0 229376 51 0 4 0 4 0 4 0 0 --- 327680 53 327680 1 0 0 0 1 0 1 393216 54 0 1 0 1 0 1 0 0 --- 786432 58 0 1 0 1 0 1 0 0 --- 1572864 62 1572864 1 0 0 0 1 0 1 --- stats.arenas.\u0026lt;i\u0026gt;.lextents.\u0026lt;j\u0026gt;.curlextents\nCurrent number of large allocations for this size class.\nextents # extents: size ind ndirty dirty nmuzzy muzzy nretained retained ntotal total 4096 0 25 102400 0 0 14 57344 39 159744 8192 1 31 253952 0 0 19 155648 50 409600 12288 2 32 393216 0 0 9 110592 41 503808 16384 3 1 16384 0 0 4 65536 5 81920 20480 4 2 40960 0 0 3 61440 5 102400 24576 5 3 73728 0 0 4 98304 7 172032 28672 6 0 0 0 0 1 28672 1 28672 32768 7 1 32768 0 0 1 32768 2 65536 40960 8 1 40960 0 0 0 0 1 40960 49152 9 0 0 0 0 2 90112 2 90112 57344 10 0 0 0 0 1 53248 1 53248 65536 11 1 65536 0 0 1 65536 2 131072 81920 12 2 159744 0 0 0 0 2 159744 98304 13 2 192512 0 0 0 0 2 192512 114688 14 1 106496 0 0 0 0 1 106496 --- 163840 16 0 0 0 0 1 139264 1 139264 196608 17 0 0 0 0 1 192512 1 192512 229376 18 1 200704 0 0 0 0 1 200704 --- 327680 20 0 0 0 0 1 311296 1 311296 --- 1048576 27 1 978944 0 0 0 0 1 978944 1310720 28 0 0 0 0 1 1167360 1 1167360 1572864 29 0 0 0 0 1 1445888 1 1445888 1835008 30 0 0 0 0 2 3493888 2 3493888 2097152 31 0 0 0 0 6 12496896 6 12496896 2621440 32 0 0 0 0 1 2420736 1 2420736 --- 参数 含义 备注 size ind ndirty dirty nmuzzy muzzy nretained retained ntotal ndirty + nmuzzy + nretained total 其他 # Bytes in small extent cache: 0 HPA shard stats: Purge passes: 0 (0 / sec) Purges: 0 (0 / sec) Hugeifies: 0 (0 / sec) Dehugifies: 0 (0 / sec) In full slabs: npageslabs: 0 huge, 0 nonhuge nactive: 0 huge, 0 nonhuge ndirty: 0 huge, 0 nonhuge nretained: 0 huge, 0 nonhuge In empty slabs: npageslabs: 0 huge, 0 nonhuge nactive: 0 huge, 0 nonhuge ndirty: 0 huge, 0 nonhuge nretained: 0 huge, 0 nonhuge size ind npageslabs_huge nactive_huge ndirty_huge npageslabs_nonhuge nactive_nonhuge ndirty_nonhuge nretained_nonhuge --- "},{"id":5,"href":"/posts/2024/01/c-%E6%A8%A1%E6%9D%BF%E5%88%86%E4%BA%AB/","title":"c++模板分享","section":"Blog","content":"c++templates基础 - 20240118.pptx\n为什么需要模版 # Bad Old Days # Reuse with cut-N-paste # struct int_node { int_node* next; int value; }; struct int_list { int_node* front; int_node* back; }; void int_list_append(int_list* l, int val); void int_list_prepend(int_list* l, int val); void int_list_clear(int_list* l); struct double_node { double_node* next; double value; }; struct double_list { double_node* front; double_node* back; }; double dbl_list_append(int_list* l, double val); void dbl_list_prepend(int_list* l, double val); void dbl_list_clear(int_list* l); Reuse with Type Erasure # #include \u0026lt;stdlib.h\u0026gt; void qsort(void *base, size_t nmemb, size_t size, int (*compare)(const void *, const void *)); int cmp_dbl(const void* va, const void* vb) { double a = *((double const*) va); double b = *((double const*) vb); if (a \u0026lt; b) return -1; else if (a == b) return 0; else return 1; } void f() { double dbl_data[4] = { 3.14159, 1.41421, 2.71828, 1.61803 }; qsort(\u0026amp;dbl_data[0], 4u, sizeof(double), \u0026amp;cmp_dbl); } Reuse with Macros # #define BUILD_COMPARE(TYPE) \\ int cmp_ ## TYPE(const void* va, const void* vb) \\ { \\ TYPE const* pa = static_cast\u0026lt;TYPE const*\u0026gt;(va); \\ TYPE const* pb = static_cast\u0026lt;TYPE const*\u0026gt;(vb); \\ if (*pa \u0026lt; *pb) return -1; \\ else if (*pa == *pb) return 0; \\ else return 1; \\ } BUILD_COMPARE(float) BUILD_COMPARE(double) void h() { float data[4] = { 4.0, 3.0, 2.0, 1.0 }; qsort(\u0026amp;data[0], 4u, sizeof(float), \u0026amp;cmp_float); //- OK qsort(\u0026amp;data[0], 4u, sizeof(float), \u0026amp;cmp_dbl); //- Error } Code Reuse # These problems have been around a long time In the 1970\u0026rsquo;s, some languages began allowing algorithms to be written in terms of types to-be-specified-later Algorithms were then instantiated on demand using type arguments This approach is now known as generic programming: ****\tC++ supports generic programming with templates 模版基础 # 分类 # thing template # This kind of template \u0026hellip; is a parametrized description of a family of \u0026hellip;\nFunction Template (c++ 98/03) Class Template (c++ 98/03) Member Function Template (c++ 98/03) Alias Template (c++11) Variable Template (c++14) lambda Template (c++20) template parameter # Type template parameters Non-type template parameters (NTTPs) Template template parameters 模版基本用法 # Function Template # Function template_ is a parametrized description of a family of _functions\nClass Template # Alias Template # Policy based design # 参考材料 # Back to Basics: Templates - Bob Steagall - CppCon 2021 # https://www.youtube.com/watch?v=XN319NYEOcE\nhttps://www.youtube.com/watch?v=2Y9XbltAfXs\nback_to_basics_templates_part_1__bob_steagall__cppcon_2021.pdf\nback_to_basics_templates_part_2__bob_steagall__cppcon_2021.pdf\nBack to Basics: Templates in C++ - Nicolai Josuttis - CppCon 2022 # https://www.youtube.com/watch?v=HqsEHG0QJXU\nCTemplates_cppcon_220918.pdf\nhttps://zhuanlan.zhihu.com/p/378360055\nC++模板元编程实战 一个深度学习框架的初步实现 (李伟) (Z-Library).pdf\n"},{"id":6,"href":"/posts/1/01/","title":"2024 06 28 Taskflow调研","section":"Blog","content":"taskflow 还在持续更新中，本文分析基于 25cb83b6688362d4b9b41f48a072607b76ee044d 版本\n背景\u0026amp;需求\u0026amp;Motivation # Taskflow 作者： Dr. Tsung-Wei Huang from：Department of Electrical and Computer Engineering University of Utah 目标：高效的并行计算加速框架。 开发高效 运行高效 header only 库，核心代码不到 1w 行，c++17 标准，使用 c++20 有优化\n解决方案 # 任务流水线搭建 # DAG 框架搭建 # Taskflow：任务图\nTask/Node：节点，代表一个任务，没有数据传递的封装，手动指定依赖关系\n任务分类 # static task： condition task：可以条件执行，动态选择 0~N 个后继节点 subflow task：运行过程中动态构建新的任务图 module task：一个 taskflow 可以作为另一个 taskflow 中的 task\n（module 并不持有 taskflow，而是引用，不能并行多个相同的 taskflow）\nasync task：异步任务\n独立的异步任务\n相当于没有前后依赖关系的 task，可以在图运行后提交，用法上和 std::async 类似\n有依赖关系的异步任务\n和 static task 相比，可以并行任务创建与任务执行的过程\n同步 # 任务间的依赖关系： conditional —\u0026gt; weak dependency 其他 \u0026ndash;\u0026gt; strong dependency 普通边 strong dependency：when all 语义 任务的 strong 入度为 0 时，任务被加入就绪队列 条件边 weak dependency：when any 语义 任务的任意 weak 满足时，立刻加入就绪队列 weak dependency 允许有环，strong dependency 不能有环\n标准库算法的 taskflow 实现 # 利用前述机制，taskflow 实现了一系列标准并行算法，用法上和标准库相似\npipeline # 利用前述的基础概念，可以实现 dag 的 pipeline 并行执行，taskflow 中也提供了封装\n调度器 # 调度算法 # 线程池 + work stealing queue + priority pop/push：队列底部\nsteal：队列顶部\nobserver # 用户可以添加定制点，观察 executor 的执行状态：\nexecutor 初始化时 执行每个任务前 执行每个任务后 class ObserverInterface { virtual ~ObserverInterface() = default; virtual void set_up(size_t num_workers) = 0; virtual void on_entry(tf::WorkerView worker_view, tf::TaskView task_view) = 0; virtual void on_exit(tf::WorkerView worker_view, tf::TaskView task_view) = 0; }; 工具 # 可视化 # 可以输出 dot 格式的任务图，通过 graphviz 等工具来可视化\nprofile # 输出 json 格式文件，包含每个 worker 上任务的执行时间、执行顺序\nhttps://taskflow.github.io/tfprof/\n示例 # static task # #include \u0026lt;taskflow/taskflow.hpp\u0026gt; // the only include you need int main(){ tf::Taskflow taskflow(\u0026#34;simple\u0026#34;); auto [A, B, C, D] = taskflow.emplace( []() { std::cout \u0026lt;\u0026lt; \u0026#34;TaskA\\n\u0026#34;; }, []() { std::cout \u0026lt;\u0026lt; \u0026#34;TaskB\\n\u0026#34;; }, []() { std::cout \u0026lt;\u0026lt; \u0026#34;TaskC\\n\u0026#34;; }, []() { std::cout \u0026lt;\u0026lt; \u0026#34;TaskD\\n\u0026#34;; } ); A.precede(B, C); // A runs before B and C D.succeed(B, C); // D runs after B and C tf::Executor executor; executor.run(taskflow).wait(); return 0; } condition task # 通过返回值，控制要下一步执行的节点（可以返回多个）\ntf::Taskflow taskflow; auto [init, cond, yes, no] = taskflow.emplace( [] () { }, [] () { return 0; }, [] () { std::cout \u0026lt;\u0026lt; \u0026#34;yes\\n\u0026#34;; }, [] () { std::cout \u0026lt;\u0026lt; \u0026#34;no\\n\u0026#34;; } ); cond.succeed(init) .precede(yes, no); // executes yes if cond returns 0 // executes no if cond returns 1 通过 condition task，可以自己封装出数据同步的逻辑： subflow task # 在任务执行过程中，动态创建新的任务图，会作为一个子图\ntf::Taskflow taskflow; tf::Task A = taskflow.emplace([] () {}).name(\u0026#34;A\u0026#34;); // static task A tf::Task C = taskflow.emplace([] () {}).name(\u0026#34;C\u0026#34;); // static task C tf::Task D = taskflow.emplace([] () {}).name(\u0026#34;D\u0026#34;); // static task D tf::Task B = taskflow.emplace([] (tf::Subflow\u0026amp; subflow) { tf::Task B1 = subflow.emplace([] () {}).name(\u0026#34;B1\u0026#34;); // subflow task B1 tf::Task B2 = subflow.emplace([] () {}).name(\u0026#34;B2\u0026#34;); // subflow task B2 tf::Task B3 = subflow.emplace([] () {}).name(\u0026#34;B3\u0026#34;); // subflow task B3 B1.precede(B3); // B1 runs before B3 B2.precede(B3); // B2 runs before B3 }).name(\u0026#34;B\u0026#34;); A.precede(B); // B runs after A A.precede(C); // C runs after A B.precede(D); // D runs after B C.precede(D); // D runs after C module task（composable task） # 把一个 taskflow 整体作为一个另一个 taskflow 的 task\ntf::Taskflow f1; f1.name(\u0026#34;F1\u0026#34;); // ... // ... 构建taskflow1中的任务 // ... // f2A --- // |----\u0026gt; f2C ----\u0026gt; f1_module_task ----\u0026gt; f2D // f2B --- tf::Taskflow f2; f2.name(\u0026#34;F2\u0026#34;); tf::Task f2A = f2.emplace([\u0026amp;]() { std::cout \u0026lt;\u0026lt; \u0026#34; F2 TaskA\\n\u0026#34;; }); tf::Task f2B = f2.emplace([\u0026amp;]() { std::cout \u0026lt;\u0026lt; \u0026#34; F2 TaskB\\n\u0026#34;; }); tf::Task f2C = f2.emplace([\u0026amp;]() { std::cout \u0026lt;\u0026lt; \u0026#34; F2 TaskC\\n\u0026#34;; }); tf::Task f2D = f2.emplace([\u0026amp;]() { std::cout \u0026lt;\u0026lt; \u0026#34; F2 TaskD\\n\u0026#34;; }); f2A.name(\u0026#34;f2A\u0026#34;); f2B.name(\u0026#34;f2B\u0026#34;); f2C.name(\u0026#34;f2C\u0026#34;); f2D.name(\u0026#34;f2D\u0026#34;); f2A.precede(f2C); f2B.precede(f2C); tf::Task f1_module_task = f2.composed_of(f1).name(\u0026#34;module\u0026#34;); f2C.precede(f1_module_task); f1_module_task.precede(f2D); async task # 没有依赖关系的异步任务 std::future\u0026lt;int\u0026gt; future = executor.async([](){ return 1; }); assert(future.get() == 1); 有依赖关系异步任务 tf::Executor executor; tf::AsyncTask A = executor.silent_dependent_async([](){ printf(\u0026#34;A\\n\u0026#34;); }); tf::AsyncTask C = executor.silent_dependent_async([](){ printf(\u0026#34;C\\n\u0026#34;); }, A); tf::AsyncTask B = executor.silent_dependent_async([](){ printf(\u0026#34;B\\n\u0026#34;); }, A); auto [D, fuD] = executor.dependent_async([](){ printf(\u0026#34;D\\n\u0026#34;); }, B, C); fuD.get(); // wait for D to finish, which in turns means A, B, C finish 并行算法 # tf::Taskflow taskflow; tf::Executor executor; std::vector\u0026lt;int\u0026gt; data = {1, 4, 9, 2, 3, 11, -8}; tf::Task sort = taskflow.sort(data.begin(), data.end()); executor.run(taskflow).wait(); assert(std::is_sorted(data.begin(), data.end())); pipeline # #include \u0026lt;taskflow/taskflow.hpp\u0026gt; #include \u0026lt;taskflow/algorithm/pipeline.hpp\u0026gt; int main() { tf::Taskflow taskflow(\u0026#34;pipeline\u0026#34;); tf::Executor executor; const size_t num_lines = 4; // custom data storage std::array\u0026lt;size_t, num_lines\u0026gt; buffer; // the pipeline consists of three pipes (serial-parallel-serial) // and up to four concurrent scheduling tokens tf::Pipeline pl(num_lines, tf::Pipe{tf::PipeType::SERIAL, [\u0026amp;buffer](tf::Pipeflow\u0026amp; pf) { // generate only 5 scheduling tokens if(pf.token() == 5) { pf.stop(); } // save the result of this pipe into the buffer else { printf(\u0026#34;stage 1: input token = %zu\\n\u0026#34;, pf.token()); buffer[pf.line()] = pf.token(); } }}, tf::Pipe{tf::PipeType::PARALLEL, [\u0026amp;buffer](tf::Pipeflow\u0026amp; pf) { printf( \u0026#34;stage 2: input buffer[%zu] = %zu\\n\u0026#34;, pf.line(), buffer[pf.line()] ); // propagate the previous result to this pipe and increment // it by one buffer[pf.line()] = buffer[pf.line()] + 1; }}, tf::Pipe{tf::PipeType::SERIAL, [\u0026amp;buffer](tf::Pipeflow\u0026amp; pf) { printf( \u0026#34;stage 3: input buffer[%zu] = %zu\\n\u0026#34;, pf.line(), buffer[pf.line()] ); // propagate the previous result to this pipe and increment // it by one buffer[pf.line()] = buffer[pf.line()] + 1; }} ); // build the pipeline graph using composition tf::Task init = taskflow.emplace([](){ std::cout \u0026lt;\u0026lt; \u0026#34;ready\\n\u0026#34;; }) .name(\u0026#34;starting pipeline\u0026#34;); tf::Task task = taskflow.composed_of(pl) .name(\u0026#34;pipeline\u0026#34;); tf::Task stop = taskflow.emplace([](){ std::cout \u0026lt;\u0026lt; \u0026#34;stopped\\n\u0026#34;; }) .name(\u0026#34;pipeline stopped\u0026#34;); // create task dependency init.precede(task); task.precede(stop); // dump the pipeline graph structure (with composition) taskflow.dump(std::cout); // run the pipeline executor.run(taskflow).wait(); return 0; } executor # tf::Executor executor; executor.run(taskflow); // execution 1 executor.run_n(taskflow, 10); // execution 2 executor.run(taskflow); // execution 3 executor.wait_for_all(); // execution 1 -\u0026gt; execution 2 -\u0026gt; execution 3 executor.run_until(taskflow, [cnt=0] () mutable { return ++cnt == 10; }); 代码结构\u0026amp;流程 # 代码结构 # core 核心代码 cuda、sycl：两种异构加速的封装 algorithm：并行算法的封装 dsl：另一种 api 形式 utility 基本流程 # 与 mediapipe 对比 # Taskflow Mediapipe DAG 搭建 用户显示指定任务间的依赖关系 根据任务间的输入输出关系，自动组合成 DAG 数据传递 基本没有封装，依靠 lambda 捕获，共享状态 通过 steam、packet 的概念，在任务间传递数据 确定性 以吞吐量为目标，没有太多确定性的考虑。work stealing queue 的设计让任务的执行顺序带有了不确定性 默认不丢弃消息、通过 side packet 的概念让每个任务都尽量是函数式，减少对状态的依赖 mediapipe 侧重于任务流水线的搭建，对数据传递也做了封装，抽象程度更高 taskflow 相对来说更底层，相当于一个带依赖关系的、高级版的线程池 Reference # taskflow 主页：https://taskflow.github.io/\ntaskflow 仓库：https://github.com/taskflow/taskflow\ntaskflow godbolt：https://godbolt.org/z/j8hx3xnnx\n作者 cppcon 演讲：https://www.youtube.com/watch?v=MX15huP5DsM\n其他 # 使用 taskflow 的项目：\nhttps://github.com/NVIDIAGameWorks/donut\n#ifdef DONUT_WITH_TASKFLOW if (executor) loadedTexture = textureCache.LoadTextureFromMemoryAsync(textureData, name, mimeType, sRGB, *executor); else #endif loadedTexture = textureCache.LoadTextureFromMemoryDeferred(textureData, name, mimeType, sRGB); https://github.com/NVIDIAGameWorks/donut/blob/2a56b06d30c6e0f68776a8eb473b19f8bb35239a/src/engine/GltfImporter.cpp#L313\n"},{"id":7,"href":"/posts/1/01/","title":"2024 07 24 Cyberrt调度调研","section":"Blog","content":" 背景\u0026amp;需求\u0026amp;目的 # 方案 # 用户接口： 主要：Component + TimerComponent 额外：Reader callback, Async 任务图搭建：通过 channel 组成 DAG，提供 AllLatest 数据同步策略 调度：ClassicScheduler + ChoreographyScheduler，用协程包装用户任务 通信：intra + shm + dds，非在线模式 blocker 用户接口（任务类型） # 数据驱动任务 Component # 代码中写明类型，实现自己的初始化、数据处理、反初始化（可选）逻辑\n配置文件中指定 channel 名称\nclass CommonComponentSample : public Component\u0026lt;Driver, Driver\u0026gt; { public: bool Init() override; bool Proc(const std::shared_ptr\u0026lt;Driver\u0026gt;\u0026amp; msg0, const std::shared_ptr\u0026lt;Driver\u0026gt;\u0026amp; msg1) override; }; CYBER_REGISTER_COMPONENT(CommonComponentSample) components { class_name : \u0026#34;CommonComponentSample\u0026#34; config { name : \u0026#34;common\u0026#34; readers { channel: \u0026#34;/apollo/prediction\u0026#34; } readers { channel: \u0026#34;/apollo/test\u0026#34; } } 时间驱动任务 TimerComponent # 代码中实现定时处理逻辑\n配置文件中指定周期\nclass TimerComponentSample : public TimerComponent { public: bool Init() override; bool Proc() override; }; CYBER_REGISTER_COMPONENT(TimerComponentSample) timer_components { class_name : \u0026#34;TimerComponentSample\u0026#34; config { name : \u0026#34;timer\u0026#34; interval : 10 } } Reader Callback # Component 由 CyberRT 框架代替用户创建数据 Reader\n用户也可以自己手动创建 Reader，并指定收到数据后的 callback\nint main(int argc, char* argv[]) { // init cyber framework apollo::cyber::Init(argv[0]); // create listener node auto listener_node = apollo::cyber::CreateNode(\u0026#34;listener\u0026#34;); // create listener auto listener = listener_node-\u0026gt;CreateReader\u0026lt;apollo::cyber::examples::proto::Chatter\u0026gt;( \u0026#34;channel/chatter\u0026#34;, MessageCallback); apollo::cyber::WaitForShutdown(); return 0; } 异步任务 Async # 对于一些自定义任务，也可以通过 cyber::Async 异步提交到调度器中运行\n#include \u0026#34;cyber/cyber.h\u0026#34; int main(int argc, char* argv[]) { // init cyber framework apollo::cyber::Init(argv[0]); auto future = apollo::cyber::Async([] { std::cout \u0026lt;\u0026lt; \u0026#34;async\u0026#34; \u0026lt;\u0026lt; std::endl; }); apollo::cyber::WaitForShutdown(); return 0; } 任务图搭建 # 通过 channel name 进行匹配组网，具体 topo 部分没细看\n主要介绍一下数据同步的方式\n数据同步策略 all latest # 第一个 channel 作为触发源，每次收到 channel 0 的消息时，检查其余 channel 是否收到过消息 如果其他 channel 都曾经收到过，取最新的一个组合成一组，传给用户 否则丢弃 触发 channel 的消息用完就消耗掉了 其他 channel 的消息会重复利用 调度 # cyber 提供两种调度策略，Classic 和 Choreography\n调度策略 # ClassicScheduler # - 多组线程池，默认是一组 - 支持为整组线程池设定同一个linux调度策略；绑核支持range / 1to1 两种方式； - 每组线程池共享N个不同优先级的任务队列 - 依次从高优先级队列到低优先级队列查找ready的任务 - 同一个优先级队列中，根据任务创建顺序遍历，有就绪的任务就执行 - 任务可以指定 所在组、优先级 调度策略\nstd::shared_ptr\u0026lt;CRoutine\u0026gt; ClassicContext::NextRoutine() { if (cyber_unlikely(stop_.load())) { return nullptr; } for (int i = MAX_PRIO - 1; i \u0026gt;= 0; --i) { ReadLockGuard\u0026lt;AtomicRWLock\u0026gt; lk(lq_-\u0026gt;at(i)); for (auto\u0026amp; cr : multi_pri_rq_-\u0026gt;at(i)) { if (!cr-\u0026gt;Acquire()) { continue; } if (cr-\u0026gt;UpdateState() == RoutineState::READY) { return cr; } cr-\u0026gt;Release(); } } return nullptr; } 调度配置文件示例\nscheduler_conf { policy: \u0026#34;classic\u0026#34; classic_conf { groups: [ { name: \u0026#34;compute\u0026#34; processor_num: 16 affinity: \u0026#34;range\u0026#34; cpuset: \u0026#34;0-7,16-23\u0026#34; processor_policy: \u0026#34;SCHED_OTHER\u0026#34; processor_prio: 0 tasks: [ { name: \u0026#34;velodyne_16_front_center_convert\u0026#34; prio: 10 }, { name: \u0026#34;msf_localization_/apollo/sensor/lidar64/compensator/PointCloud2\u0026#34; prio: 20 } ] }, { name: \u0026#34;compute_camera\u0026#34; processor_num: 16 affinity: \u0026#34;range\u0026#34; cpuset: \u0026#34;8-15,24-31\u0026#34; processor_policy: \u0026#34;SCHED_OTHER\u0026#34; processor_prio: 0 tasks: [ { name: \u0026#34;camera_front_6mm_compress\u0026#34; prio: 0 }, { name: \u0026#34;camera_rear_6mm_compress\u0026#34; prio: 0 } ] } ] } } ChoreographyScheduler # - N个choreography线程 + 一组classic线程池 - 调度策略设置上，所有choreography线程相当于一组，可以设定同一个调度策略，绑核支持 range / 1to1 两种方式 - 任务队列 - 每个choreography线程有一个优先级队列（multimap），按照迭代器顺序遍历，有就绪的任务就执行 - classic线程池和ClassicScheduler相同，但只有一组 - 任务可以指定 所在线程/组、优先级 调度策略\nstd::shared_ptr\u0026lt;CRoutine\u0026gt; ChoreographyContext::NextRoutine() { if (cyber_unlikely(stop_.load())) { return nullptr; } ReadLockGuard\u0026lt;AtomicRWLock\u0026gt; lock(rq_lk_); for (auto it : cr_queue_) { auto cr = it.second; if (!cr-\u0026gt;Acquire()) { continue; } if (cr-\u0026gt;UpdateState() == RoutineState::READY) { return cr; } cr-\u0026gt;Release(); } return nullptr; } 调度配置文件示例\nscheduler_conf { policy: \u0026#34;choreography\u0026#34; choreography_conf { choreography_processor_num: 8 choreography_affinity: \u0026#34;range\u0026#34; choreography_cpuset: \u0026#34;0-7\u0026#34; pool_processor_num: 12 pool_affinity: \u0026#34;range\u0026#34; pool_cpuset: \u0026#34;8-11,16-23\u0026#34; tasks: [ { name: \u0026#34;planning_/apollo/perception/traffic_light\u0026#34; processor: 7 prio: 17 }, { name: \u0026#34;rtk_localization\u0026#34; processor: 7 }, { name: \u0026#34;camera_rear_6mm_compress\u0026#34; prio: 3 } ] } } Processor # 取下一个 ready 的协程任务并执行\n没有任务就等待\ncode\nvoid Processor::Run() { // ... while (cyber_likely(running_.load())) { if (cyber_likely(context_ != nullptr)) { auto croutine = context_-\u0026gt;NextRoutine(); if (croutine) { snap_shot_-\u0026gt;execute_start_time.store(cyber::Time::Now().ToNanosecond()); snap_shot_-\u0026gt;routine_name = croutine-\u0026gt;name(); croutine-\u0026gt;Resume(); croutine-\u0026gt;Release(); } else { snap_shot_-\u0026gt;execute_start_time.store(0); context_-\u0026gt;Wait(); } } else { // ... } } } 协程 # 从执行效率角度，可能和普通线程池没有太大差别\n每个 component 对应的协程，生命周期和 component 相同，不需要频繁动态创建和销毁\n协程的 context 用了一个全局的对象池，减少动态内存分配\nCRoutine::CRoutine(const std::function\u0026lt;void()\u0026gt; \u0026amp;func) : func_(func) { std::call_once(pool_init_flag, [\u0026amp;]() { // ... context_pool.reset(new base::CCObjectPool\u0026lt;RoutineContext\u0026gt;(routine_num)); }); context_ = context_pool-\u0026gt;GetObject(); if (context_ == nullptr) { AWARN \u0026lt;\u0026lt; \u0026#34;Maximum routine context number exceeded! Please check \u0026#34; \u0026#34;[routine_num] in config file.\u0026#34;; context_.reset(new RoutineContext()); } MakeContext(CRoutineEntry, this, context_.get()); state_ = RoutineState::READY; updated_.test_and_set(std::memory_order_release); } 感觉更多的好处是编码方便：同步编码，异步执行：阻塞逻辑只会挂起协程自身，不会阻塞整个线程\nsleep\n// 用户sleep接口 static inline void USleep(useconds_t usec) { auto routine = croutine::CRoutine::GetCurrentRoutine(); if (routine == nullptr) { std::this_thread::sleep_for(std::chrono::microseconds{usec}); } else { routine-\u0026gt;Sleep(croutine::Duration(usec)); } } // CRoutine sleep inline void CRoutine::Sleep(const Duration \u0026amp;sleep_duration) { wake_time_ = std::chrono::steady_clock::now() + sleep_duration; CRoutine::Yield(RoutineState::SLEEP); } // CRoutine wakeup inline RoutineState CRoutine::UpdateState() { // Synchronous Event Mechanism if (state_ == RoutineState::SLEEP \u0026amp;\u0026amp; std::chrono::steady_clock::now() \u0026gt; wake_time_) { state_ = RoutineState::READY; return state_; } // Asynchronous Event Mechanism if (!updated_.test_and_set(std::memory_order_release)) { if (state_ == RoutineState::DATA_WAIT || state_ == RoutineState::IO_WAIT) { state_ = RoutineState::READY; } } return state_; } io wait / data wait\n// yield inline void CRoutine::Yield(const RoutineState \u0026amp;state) { auto routine = GetCurrentRoutine(); routine-\u0026gt;set_state(state); SwapContext(GetCurrentRoutine()-\u0026gt;GetStack(), GetMainStack()); } inline void CRoutine::Yield() { SwapContext(GetCurrentRoutine()-\u0026gt;GetStack(), GetMainStack()); } // update inline void CRoutine::SetUpdateFlag() { updated_.clear(std::memory_order_release); } 状态机\n示例：poll_handler\nvoid Echo(const std::shared_ptr\u0026lt;Session\u0026gt;\u0026amp; session) { struct sockaddr_in client_addr; std::vector\u0026lt;char\u0026gt; recv_buffer(2049); int nbytes = 0; socklen_t sock_len = static_cast\u0026lt;socklen_t\u0026gt;(sizeof(client_addr)); while (true) { nbytes = static_cast\u0026lt;int\u0026gt;( session-\u0026gt;RecvFrom(recv_buffer.data(), recv_buffer.size(), 0, (struct sockaddr*)\u0026amp;client_addr, \u0026amp;sock_len)); if (nbytes \u0026lt; 0) { std::cout \u0026lt;\u0026lt; \u0026#34;recv from client failed.\u0026#34; \u0026lt;\u0026lt; std::endl; continue; } session-\u0026gt;SendTo(recv_buffer.data(), nbytes, 0, (const struct sockaddr*)\u0026amp;client_addr, sock_len); } } bool PollHandler::Block(int timeout_ms, bool is_read) { // ... Fill(timeout_ms, is_read); // 注册回调 // ... // 挂起协程 routine_-\u0026gt;Yield(RoutineState::IO_WAIT); // ... return result; } void PollHandler::Fill(int timeout_ms, bool is_read) { // ... // 注册回调 request_.callback = std::bind(\u0026amp;PollHandler::ResponseCallback, this, std::placeholders::_1); } void PollHandler::ResponseCallback(const PollResponse\u0026amp; rsp) { // ... if (routine_-\u0026gt;state() == RoutineState::IO_WAIT) { // 回调中让调度器更新协程状态 scheduler::Instance()-\u0026gt;NotifyTask(routine_-\u0026gt;id()); /* NotifyTask -\u0026gt; NotifyProcessor -\u0026gt; cr-\u0026gt;SetUpdateFlag(); */ } } 任务对应的协程 # 数据驱动任务 # std::shared_ptr\u0026lt;M0\u0026gt; msg0; std::shared_ptr\u0026lt;M1\u0026gt; msg1; std::shared_ptr\u0026lt;M2\u0026gt; msg2; std::shared_ptr\u0026lt;M3\u0026gt; msg3; for (;;) { CRoutine::GetCurrentRoutine()-\u0026gt;set_state(RoutineState::DATA_WAIT); if (dv-\u0026gt;TryFetch(msg0, msg1, msg2, msg3)) { f(msg0, msg1, msg2, msg3); CRoutine::Yield(RoutineState::READY); } else { CRoutine::Yield(); } } 时间驱动任务 \u0026amp; 异步任务 # cyberRT 中有一个全局的协程池，TaskManager；\nTaskManager 会往调度器里添加 N 个 CRoutine 任务（/internal/task0、…、/internal/taskx），实际由调度器进行调度执行\nTaskManager 中每个协程的任务是从任务队列中取任务并执行\nTaskManager::TaskManager() : task_queue_size_(1000), task_queue_(new base::BoundedQueue\u0026lt;std::function\u0026lt;void()\u0026gt;\u0026gt;()) { // ... auto func = [this]() { while (!stop_) { std::function\u0026lt;void()\u0026gt; task; if (!task_queue_-\u0026gt;Dequeue(\u0026amp;task)) { auto routine = croutine::CRoutine::GetCurrentRoutine(); routine-\u0026gt;HangUp(); continue; } task(); } }; num_threads_ = scheduler::Instance()-\u0026gt;TaskPoolSize(); auto factory = croutine::CreateRoutineFactory(std::move(func)); tasks_.reserve(num_threads_); for (uint32_t i = 0; i \u0026lt; num_threads_; i++) { auto task_name = task_prefix + std::to_string(i); tasks_.push_back(common::GlobalData::RegisterTaskName(task_name)); if (!scheduler::Instance()-\u0026gt;CreateTask(factory, task_name)) { AERROR \u0026lt;\u0026lt; \u0026#34;CreateTask failed:\u0026#34; \u0026lt;\u0026lt; task_name; } } } Async 会把任务加进协程池的任务队列\ntemplate \u0026lt;typename F, typename... Args\u0026gt; static auto Async(F\u0026amp;\u0026amp; f, Args\u0026amp;\u0026amp;... args) -\u0026gt; std::future\u0026lt;typename std::result_of\u0026lt;F(Args...)\u0026gt;::type\u0026gt; { return GlobalData::Instance()-\u0026gt;IsRealityMode() ? TaskManager::Instance()-\u0026gt;Enqueue(std::forward\u0026lt;F\u0026gt;(f), std::forward\u0026lt;Args\u0026gt;(args)...) : std::async( std::launch::async, std::bind(std::forward\u0026lt;F\u0026gt;(f), std::forward\u0026lt;Args\u0026gt;(args)...)); } 时间驱动任务额外维护一个时间轮线程，时间轮线程负责定时调用 Async tick_thread_ = std::thread([this]() { this-\u0026gt;TickFunc(); }); void TimingWheel::TickFunc() { Rate rate(TIMER_RESOLUTION_MS * 1000000); // ms to ns while (running_) { Tick(); // ... rate.Sleep(); // ... } } void TimingWheel::Tick() { auto\u0026amp; bucket = work_wheel_[current_work_wheel_index_]; { std::lock_guard\u0026lt;std::mutex\u0026gt; lock(bucket.mutex()); auto ite = bucket.task_list().begin(); while (ite != bucket.task_list().end()) { auto task = ite-\u0026gt;lock(); if (task) { ADEBUG \u0026lt;\u0026lt; \u0026#34;index: \u0026#34; \u0026lt;\u0026lt; current_work_wheel_index_ \u0026lt;\u0026lt; \u0026#34; timer id: \u0026#34; \u0026lt;\u0026lt; task-\u0026gt;timer_id_; auto* callback = reinterpret_cast\u0026lt;std::function\u0026lt;void()\u0026gt;*\u0026gt;(\u0026amp;(task-\u0026gt;callback)); cyber::Async([this, callback] { if (this-\u0026gt;running_) { (*callback)(); } }); } ite = bucket.task_list().erase(ite); } } } reader # 每个 reader 会对应一个 CRoutine 任务 如果用户创建 Reader 时指定了 callback，会在这个协程任务中取数据并执行 callback callback 在 croutine 的上下文执行，通信线程只负责通知 template \u0026lt;typename MessageT\u0026gt; bool Reader\u0026lt;MessageT\u0026gt;::Init() { // ... std::function\u0026lt;void(const std::shared_ptr\u0026lt;MessageT\u0026gt;\u0026amp;)\u0026gt; func; if (reader_func_ != nullptr) { func = [this](const std::shared_ptr\u0026lt;MessageT\u0026gt;\u0026amp; msg) { this-\u0026gt;Enqueue(msg); this-\u0026gt;reader_func_(msg); }; } else { func = [this](const std::shared_ptr\u0026lt;MessageT\u0026gt;\u0026amp; msg) { this-\u0026gt;Enqueue(msg); }; } auto sched = scheduler::Instance(); croutine_name_ = role_attr_.node_name() + \u0026#34;_\u0026#34; + role_attr_.channel_name(); // ... if (!sched-\u0026gt;CreateTask(factory, croutine_name_)) { // ... } // ... return true; } scheduler 相关代码结构 # 初始化大致流程\n附录 # 线程情况 # 1: 主线程 2: 异步 log 线程 async logger 3-18: 调度器线程：执行 CRoutine 的线程池，数量取决于配置文件，默认等于 core 数量 19-24: fastrtps 相关线程 19: eprosima::fastrtps::rtps::UDPv4Transport 20: eprosima::fastrtps::rtps::ResourceEvent::run_io_service 21: eprosima::fastrtps::rtps::ReceiverResource::Receive 22: eprosima::fastrtps::rtps::UDPv4Transport::Receive 23: eprosima::fastrtps::rtps::UDPv4Transport::Receive 24: eprosima::fastrtps::rtps::AsyncWriterThread::run 25: 共享内存线程 apollo::cyber::transport::ShmDispatcher::ThreadFunc() 26: 时间轮线程 apollo::cyber::TimingWheel::TickFunc() 和 mediapipe、Taskflow 对比 # DAG 搭建 数据同步方式：mediapipe 更灵活，种类更多 调度： cyber 调度策略更灵活，支持自定义任务优先级； mediapipe 支持定制执行器，但不支持定制调度策略；可以通过分组实现和 cyber 类似的效果 通信：cyber 支持跨进程 具体线程池的实现上，也许可以参考 Taskflow reference # cyber rt 协程具体实现的解析： https://blog.csdn.net/jinzhuojun/article/details/86760743 https://blog.csdn.net/lizhipengcsdn/article/details/131236278 "},{"id":8,"href":"/posts/1/01/","title":"2024 12 12 Taskflow如何工作","section":"Blog","content":" 运行机制 # Executor # 构造函数，可以看出来它的成员：\nN 个线程 N 个 Worker，每个 Worker 一个线程 Notifier，负责线程之间通知的 Latch，负责主线程和 Worker 线程的初始化的同步的 FreeList，一个有锁队列，主线程提交任务时就会往这里填充，或者 Worker 线程提交任务时，发现 Worker 自己的队列满了就往 FreeList 提交 Executor 的构造函数中初始化了 thread local 的 Worker，创建 N 个线程，每个线程是一个 while(1)，等待 task、执行 task。\nExecutor::Executor(size_t N) -》_spawn(N)：\nExecutor 也是有两级的链表：\n第一级是 Executor 会有以及，它是无界、lock-free 队列（Push 有锁，但是 Steal 是无锁的，也就是说适合单生产者 - 多消费者场景）：Freelist\u0026lt;Node*\u0026gt; _freelist; 第二级是每个 Worker 都有一个有界的、lock-free 队列：BoundedTaskQueue\u0026lt;Node*\u0026gt; _wsq; Executor 的 run 函数，会将没有 depends 的 node 直接放入到 freelist 中，这样整个 graph 就可以运转起来了：\nWorker 线程会从 freelist steal 到 Node，然后调用 _invoke 来执行 Node，invoke task 的时候会判断它的 _successors 的情况，如果 join_counter 为了 0，则 graph 的下游 Node 可以被调度了（放入队列，或者放到 worker._cache 中直接 goto 执行）：\nTask # 基本就是对 Node 的封装。\nNode # node 是 Graph 中的一个节点，成员变量：\nstd::atomic\u0026lt;int\u0026gt; _state {0}; std::string _name; void* _data {nullptr}; Topology* _topology {nullptr}; Node* _parent {nullptr}; // 这两个描述的就是上下游的链接关系 SmallVector\u0026lt;Node*\u0026gt; _successors; SmallVector\u0026lt;Node*\u0026gt; _dependents; // 描述当前Node的是否Ready的入度 std::atomic\u0026lt;size_t\u0026gt; _join_counter {0}; std::exception_ptr _exception_ptr {nullptr}; // 可执行函数 handle_t _handle; Node 有多种类型：\nGraph # 成员变量：很简单，只有一个 vector\nstd::vector\u0026lt;Node*\u0026gt; _nodes; Runtime # Executor 在执行一个 Node 时，需要根据其类型来判断以何种方式调用。具体应用参考这个：https://taskflow.github.io/taskflow/RuntimeTasking.html，一种动态调度 Node 的方式，脱离 DAG 的一种执行 Node 的方式，看起来有点太灵活了，不知道用于什么场景。\n解释：\n成员变量：\nExecutor 的某种场景：\nTopology # 成员变量：\nTaskflow\u0026amp; _taskflow; std::promise\u0026lt;void\u0026gt; _promise; SmallVector\u0026lt;Node*\u0026gt; _sources; std::function\u0026lt;bool()\u0026gt; _pred; std::function\u0026lt;void()\u0026gt; _call; std::atomic\u0026lt;size_t\u0026gt; _join_counter {0}; std::atomic\u0026lt;int\u0026gt; _state {CLEAN}; std::exception_ptr _exception_ptr {nullptr}; Executor 的 run_until 函数会创建一个 Topology，每次运行都创建一个 Topology，所以 Taskflow 中是一个 Topology 的 vector，Taskflow 可以多次提交给 Executor，每次都会创建一个 Topology，可能是记录本次运行的情况。\nTaskflow # 成员变量：\nmutable std::mutex _mutex; std::string _name; Graph _graph; std::queue\u0026lt;std::shared_ptr\u0026lt;Topology\u0026gt;\u0026gt; _topologies; std::optional\u0026lt;std::list\u0026lt;Taskflow\u0026gt;::iterator\u0026gt; _satellite; Pipeline # Pipeline 实际是创建了一个 Module Task：\n这里实际是重新 setup 了一个 graph，并开始调度：\n这个 until 很有意思，为了不空等，它实际是一个 while 循环，里面还是在执行 Node，只不过会有终止条件，就是 until 的第二个参数：\n针对 Pipeline 实际上又创建了一个 Pipeflow，而且针对是串行还是并行，两次 line 之间是有依赖关系的：\n1 -\u0026gt; 2 -\u0026gt; 3 | | | v v v 1 -\u0026gt; 2 -\u0026gt; 3 和下面的图是不一样的： 1 -\u0026gt; 2 -\u0026gt; 3 | v 1 -\u0026gt; 2 -\u0026gt; 3 这个图允许2和3 pipe并行执行，但是1要求是必须串行执行 同时对于 Pipe 的执行，也是在一个 Module Task 中执行的，它内部用 goto 实现了一个循环，所以 Pipe 和 Task（Node）都没有关联关系：\n同时看起来它也不支持复杂的 pipeline，每条 line 只有一个分支，不能将一个复杂的 DAG 作为一条 line。\nTaskflow 的问题 # 不能适用于我们场景的一些问题。\nExecutor 和 Graph 耦合比较深 # Executor 中直接使用了 Node，但是 Node 其实是 Graph 的组成部分，相当于 Graph 和 Executor 耦合的比较深，感觉需要一个中间的概念将它俩联系起来比较好，或者至少和 Mediapipe 一样，通过回调的方式分离 Scheduler 和 CalculatorNode 的一些逻辑（当然还是有一些耦合的），起码 Mediapipe 的 Executor 和 Calculator 是完全分离的，没有依赖关系，所以可以简单的替换掉 Executor。\n所以 Taskflow 的 Executor 可以拆成两部分：Scheduler 和 Executor，Scheduler 负责和 Graph 打交道，Executor 可以更干净一些。\n缺少数据流抽象 # 缺少数据层抽象，虽然有 DataPipeline，但是它的流水线只能是简单的一条分支，不能是一个复杂的 DAG 图。\n"},{"id":9,"href":"/posts/1/01/","title":"2024 12 25 Cgraph调研","section":"Blog","content":"repo：https://github.com/ChunelFeng/CGraph\n功能 # 建立依赖图关系：GPipeline、GNode（T00/T01） # 一条 pipeline 是从头执行到尾的，其实是 graph 的概念，没有流水线的功能 status += pipeline-\u0026gt;registerGElement\u0026lt;MyNode2\u0026gt;(\u0026amp;b, {a}, \u0026#34;nodeB\u0026#34;); // 将名为nodeB，依赖a执行的node信息，注册入pipeline中 子图：Cluster / Region：类似 subgraph，互相可嵌套（T02/T03/T04） # cluster：subgraph 中的多个节点串行执行 http://www.chunel.cn/archives/cgraph-run-introduce 这个解释感觉有点奇怪，D/F 未能并行执行是实现机制的问题，感觉不需要引入新的概念来解决。 region：可以是 DAG 图 b_cluster = pipeline-\u0026gt;createGGroup\u0026lt;GCluster\u0026gt;({ pipeline-\u0026gt;createGNode\u0026lt;MyNode1\u0026gt;(GNodeInfo(\u0026#34;nodeB1\u0026#34;, 1)), // 创建名为nodeB1的node信息，并将其放入b_cluster中 pipeline-\u0026gt;createGNode\u0026lt;MyNode1\u0026gt;(GNodeInfo(\u0026#34;nodeB2\u0026#34;, 3)), // 创建名为nodeB2且自循环3次的node信息，并将其放入b_cluster中 pipeline-\u0026gt;createGNode\u0026lt;MyNode2\u0026gt;(GNodeInfo(\u0026#34;nodeB3\u0026#34;, 1)) }); // 创建cluster信息，包含了三个node信息 b_region = pipeline-\u0026gt;createGGroup\u0026lt;GRegion\u0026gt;({b1, b2, b3, b4}); // 将 b1、b2、b3、b4 注册入b_region中 参数传递：param (T05) # 相当于是一个 map，同一个 pipeline 中各个节点共享的全局参数。\n// 创建 status = CGRAPH_CREATE_GPARAM(MyParam, \u0026#34;param1\u0026#34;) // 读取 auto* myParam = CGRAPH_GET_GPARAM_WITH_NO_EMPTY(MyParam, \u0026#34;param1\u0026#34;) // 写入 CGRAPH_PARAM_WRITE_CODE_BLOCK(myParam) 条件选择：Condition （T06） # 根据 choose 返回值，来决定下一步运行哪一个节点。\nchoose 函数里，可以通过 param 来获取到外界信息，做一些判断。\nb_condition = pipeline-\u0026gt;createGGroup\u0026lt;MyCondition\u0026gt;({ pipeline-\u0026gt;createGNode\u0026lt;MyNode1\u0026gt;(GNodeInfo(\u0026#34;conditionNodeB0\u0026#34;, 1)), pipeline-\u0026gt;createGNode\u0026lt;MyNode2\u0026gt;(GNodeInfo(\u0026#34;conditionNodeB1\u0026#34;, 1)), pipeline-\u0026gt;createGNode\u0026lt;MyNode1\u0026gt;(GNodeInfo(\u0026#34;conditionNodeB2\u0026#34;, 1)) }); // 生成 b_condition。执行的时候，根据choose()的返回值，在B0,B1,B2中选择一个执行 多条 pipeline (T07) # 手动指定线程池 // 创建线程池 UThreadPoolConfig config; config.default_thread_size_ = 4; config.max_thread_size_ = 4; config.monitor_enable_ = false; UThreadPool pool(true, config); // 开辟一个4个线程的线程池，直接 init，并且参数设置为 config // 指定pipeline使用的线程池 pipeline_1-\u0026gt;setSharedThreadPool(\u0026amp;pool); // 多个pipeline，可以共享同一个线程池 pipeline_2-\u0026gt;setSharedThreadPool(\u0026amp;pool); 异步执行 n 次： 只是包装了一下 std::async，没有其他特殊处理 return pipeline_1-\u0026gt;asyncProcess(5); // std::future\u0026lt;CStatus\u0026gt; 有初始化参数的 GNode (T08) # 会用传入的参数，初始化这个 node。 pipeline-\u0026gt;registerGElement\u0026lt;MyTemplateNode\u0026lt;int, float\u0026gt;\u0026gt;(\u0026amp;a, {}, 3, 3.5f); 切面 GAspect ：（T09/T10） # Observer，可以在几个执行点前后（init/run/destroy）插入逻辑。 a-\u0026gt;addGAspect\u0026lt;MyTraceAspect\u0026gt;(); a-\u0026gt;addGAspect\u0026lt;MyTemplateAspect\u0026lt;int, double\u0026gt;\u0026gt;(20, 7.0); // 继承GAspect之后，实现逻辑，beginInit、finishInit、beginRun、finishRun、beginDestroy、finishDestroy 可以通过切面参数，来传递一些信息 // 构造图的时候，addGAspect传入参数 a-\u0026gt;addGAspect\u0026lt;MyConnAspect, MyConnParam\u0026gt;(\u0026amp;paramA); // Aspect中，getAParam\u0026lt;MyConnParam\u0026gt;()获取参数 CStatus beginInit() override { auto* param = this-\u0026gt;getAParam\u0026lt;MyConnParam\u0026gt;(); // 注意，这里是AParam，表示的是切面自己的参数，不是GParam if (param) { // 如果传入类型不匹配，则返回param值为空 mockConnect(param-\u0026gt;ip_, param-\u0026gt;port_); } return CStatus(); } Singleton 节点（T11） # 单例 CFunction 节点（T12） # 用来把一个 lambda 构造成节点。 通过捕获列表，可以不通过 Param 功能传入传出一些信息，相当于开了个口子？ 看作者的介绍，也是不推荐这种用法，而是为了老代码的快速迁移 http://www.chunel.cn/archives/cgraph-function-introduce\nGFunctionPtr c_function, d_function = nullptr; // 申明两个 GFunction 类型的变量 // 注册 status += pipeline-\u0026gt;registerGElement\u0026lt;GFunction\u0026gt;(\u0026amp;c_function, {b}, \u0026#34;functionC\u0026#34;, 1); // 注册GFunction类型的节点c_function // 设置回调，可以设置多个 int num = 10; d_function-\u0026gt;setFunction(CFunctionType::INIT, [d_function] { CGRAPH_ECHO(\u0026#34;[%s] do init function ...\u0026#34;, d_function-\u0026gt;getName().c_str()); return CStatus(); })-\u0026gt;setFunction(CFunctionType::RUN, [d_function, num] { auto param = d_function-\u0026gt;getGParamWithNoEmpty\u0026lt;MyParam\u0026gt;(\u0026#34;param1\u0026#34;); param-\u0026gt;iCount += num; CGRAPH_ECHO(\u0026#34;[%s] do run function, iCount = [%d], iValue = [%d] ...\u0026#34;, d_function-\u0026gt;getName().c_str(), param-\u0026gt;iCount, ++param-\u0026gt;iValue); return CStatus(); }); 定时任务：Daemon（T13） # pipeline-\u0026gt;addGDaemon\u0026lt;MyMonitorDaemon\u0026gt;(4000) // 间隔4s执行 -\u0026gt;addGDaemon\u0026lt;MyParamDaemon, MyConnParam\u0026gt;(3500, \u0026amp;connParam) // 间隔3500ms执行，并且传入参数 -\u0026gt;addGDaemon\u0026lt;MyTemplateDaemon\u0026lt;int\u0026gt;\u0026gt;(2750, 300); // 添加模板daemon信息 Hold 机制：（T14） # 通过一个条件，判断节点是否继续重复执行 为什么不直接在 run 里作为循环条件？ 不过相当于加了一个调度点 CBool isHold() override { /** * 针对当前场景，添加 hold逻辑 * 当 hold逻辑被满足的时候，会重复执行当前节点，直到返回false为止 * 也可以用isHold机制，实现算子内部自己的状态机机制 */ auto param = CGRAPH_GET_GPARAM(MyParam, HOLD_PARAM_NAME) if (nullptr == param) { return false; // 如果未读取到参数，则直接结束，不继续执行了 } CGraph::CGRAPH_ECHO(\u0026#34;enter hold path, iValue = [%d]\u0026#34;, param-\u0026gt;iValue); return param-\u0026gt;iValue \u0026lt; 5; // 当 iValue 值小于5的时候，此节点会持续执行 } 参数：EParam（T15） # 更像 side_packet，不在 pipeline 中共享，节点独有。 // 给节点添加参数 v1-\u0026gt;addEParam(VERSION_PARAM_KEY, \u0026amp;vp1); // 节点内部获取参数 auto* version = CGRAPH_GET_EPARAM(MyVersionParam, VERSION_PARAM_KEY) if (nullptr != version) { CGraph::CGRAPH_ECHO(\u0026#34;[%s] version is [%d-%d]\u0026#34;, this-\u0026gt;getName().c_str(), version-\u0026gt;priority_, version-\u0026gt;secondary_); } 消息传递：Message（T16、T17） # 前面的 param，只能在单个 pipeline 中共享数据。 Message，可以在多个 pipeline 之间传递消息。 send/recv：一发一收，channel。 // 发送 std::unique_ptr\u0026lt;MyMessageParam\u0026gt; mp(new MyMessageParam()); CStatus status = CGRAPH_SEND_MPARAM(MyMessageParam, \u0026#34;send-recv\u0026#34;, mp, CGraph::GMessagePushStrategy::WAIT) // 接收 std::unique_ptr\u0026lt;MyMessageParam\u0026gt; mp = nullptr; // 接收一个消息 CStatus status = CGRAPH_RECV_MPARAM(MyMessageParam, \u0026#34;send-recv\u0026#34;, mp); pub/sub：一发多收 // 发送 MyMessageParam mp; // 创建一个消息，并且发送出去 CStatus status = CGRAPH_PUB_MPARAM(MyMessageParam, \u0026#34;pub-sub\u0026#34;, mp, CGraph::GMessagePushStrategy::WAIT); // 接收 std::unique_ptr\u0026lt;MyMessageParam\u0026gt; mp = nullptr; // 通过智能指针类型，接收一个消息。相比value接收(Recv or Sub)，性能会好一些 CStatus status = CGRAPH_SUB_MPARAM(MyMessageParam, conn_id_, mp) 事件：Event（T18） # 方便在一些特定的条件下，触发一段逻辑的执行。可以同步/异步 // 构建pipeline时，可以添加event触发后的执行逻辑 pipeline-\u0026gt;addGEvent\u0026lt;MyPrintEvent\u0026gt;(\u0026#34;my-print-event\u0026#34;); // 在graph的执行过程中，node内部可以通过notify来触发一段逻辑的执行 notify(\u0026#34;my-print-event\u0026#34;, GEventType::SYNC); 执行控制（T19、T20） # 可以对 pipeline 的执行进行一定的控制\n取消：（T19） pipeline-\u0026gt;cancel() yield/resume（T20） status += pipeline-\u0026gt;yield(); // 暂停执行，保留当前pipeline内部所有参数信息和状态信息 status += pipeline-\u0026gt;resume(); // 暂停一段时间后，恢复执行 条件选择：MultiCondition（T21） # 可以把几个 node 组合到一起 node 中，override isMatch 方法，来决定是否需要执行 b_multi_condition = pipeline-\u0026gt;createGGroup\u0026lt;GMultiCondition\u0026lt;GMultiConditionType::SERIAL\u0026gt;\u0026gt;({ pipeline-\u0026gt;createGNode\u0026lt;MyNode1\u0026gt;(GNodeInfo(\u0026#34;nodeB1\u0026#34;)), // 本节点【不会】执行，因为默认不执行 pipeline-\u0026gt;createGNode\u0026lt;MyMatchNode\u0026gt;(GNodeInfo(\u0026#34;nodeB2\u0026#34;)) // 本节点【会】执行，因为 isMatch() 返回为 true }); 超时：Timeout（T22） # Some：任意一个完成，即可触发后续任务（T23） # Fence：用来等待异步任务结束（T24） # Coordinator：运行过程中，动态调整线程数（T25） # Mutable：运行过程中，动态调整依赖关系（T26） # reshape\nCStatus reshape(CGraph::GElementPtrArr\u0026amp; elements) override { auto param = CGRAPH_GET_GPARAM_WITH_NO_EMPTY(MyParam, \u0026#34;param1\u0026#34;) int count = param-\u0026gt;iCount % 4; if (0 == count) { CGraph::CGRAPH_ECHO(\u0026#34;---- run as a-\u0026gt;[b,c]\u0026#34;); (*elements[0])--\u0026gt;elements[1] \u0026amp; elements[2]; } // ... return CStatus(); } trim()：删除不必要的依赖关系（T27） # pipeline-\u0026gt;registerGElement\u0026lt;MyNode1\u0026gt;(\u0026amp;a, {}, \u0026#34;nodeA\u0026#34;); pipeline-\u0026gt;registerGElement\u0026lt;MyNode2\u0026gt;(\u0026amp;b, {a}, \u0026#34;nodeB\u0026#34;); pipeline-\u0026gt;registerGElement\u0026lt;MyNode1\u0026gt;(\u0026amp;c, {a}, \u0026#34;nodeC\u0026#34;); /** * 可以看出，d节点 对a 的依赖，是可有可无的 * 建议通过 trim() 接口删除冗余依赖 * 参考文档：http://www.chunel.cn/archives/cgraph-remove-redundancy-link */ pipeline-\u0026gt;registerGElement\u0026lt;MyNode2\u0026gt;(\u0026amp;d, {a, b, c}, \u0026#34;nodeD\u0026#34;); auto trimSize = pipeline-\u0026gt;trim(); 线程池（TU01） # 提交任务 commit 非阻塞接口 auto r1 = tp-\u0026gt;commit([i, j] { return add(i, j); }); - submit：阻塞接口 ```C++ tp-\u0026gt;submit([i] { std::cout \u0026lt;\u0026lt; i \u0026lt;\u0026lt; \u0026quot; \u0026quot;; }); // 可以看到，submit版本是有序执行的。如果需要想要无序执行，可以通过创建taskGroup的方式进行，或者使用commit方法 ``` taskGroup：可以把一组任务，放到一起提交，来统一设置超时时间\nUTaskGroup taskGroup; /** 添加一个耗时为1000ms的任务 */ taskGroup.addTask([i, j] { int result = i + j; CGRAPH_SLEEP_MILLISECOND(1000) CGRAPH_ECHO(\u0026#34;sleep for 1 second, [%d] + [%d] = [%d], run success.\u0026#34;, i, j, result); }); CStatus status = tp-\u0026gt;submit(taskGroup, 2500); "},{"id":10,"href":"/posts/1/01/","title":"2024 12 26 Ubuntu20.04源码编译cyber Rt 10.0.0","section":"Blog","content":" 安装 fastdds # apollo 给的环境是一个 docker。third_party 里 fastdds 的 bazel build 直接通过系统路径依赖的 fastdds。\n自己的环境中没有，手动安装一下，看文档是说 10.0.0 升级到了 2.x 版本。\n参考 fastdds 官网文档安装一下。\nhttps://fast-dds.docs.eprosima.com/en/latest/installation/binaries/binaries_linux.html\n二进制版本，下载解压，sudo install.sh\n装不上 python3-xmlschema 换成 pip3 install xmlschema，然后注释掉脚本里的 python3-xmlschema clone foonathan_memory_vendor 报错；手动进入到该文件夹后 build 通过 cmake 版本不匹配，要求最低 3.20，但是自带的是 3.16。升级麻烦，直接替换了。按照经验大部分人都是随便写个版本，实际根本没用到什么新功能。 编译通过\ncyber rt # 把 third_party 里的 fastdds/uuid 依赖加上。\n还缺 bvar。\n安装 bvar # install_pkg_repo.sh 脚本里安装的。\n# 添加 Apollo 的 GPG 密钥 curl -fsSL https://apollo-pkg-beta.cdn.bcebos.com/neo/beta/key/deb.gpg.key | sudo gpg --dearmor -o /etc/apt/keyrings/apolloauto.gpg # 添加 Apollo 的软件源 echo \u0026#34;deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/apolloauto.gpg] https://apollo-pkg-beta.cdn.bcebos.com/apollo/core $(. /etc/os-release \u0026amp;\u0026amp; echo \u0026#34;$VERSION_CODENAME\u0026#34;) main\u0026#34; | sudo tee /etc/apt/sources.list.d/apolloauto.list sudo apt update sudo apt-get install bvar 装不上，有人提 issue：\nhttps://github.com/ApolloAuto/apollo/issues/15614\n这个库里有 deb：\nhttps://github.com/minhanghuang/CyberRT/tree/v10.0.0-rc1\nsudo dpkg -i xxx.deb 不知为何有个这个 define，报了一堆 fastdds 的错，注释掉之后编译通过\n依赖 cyber rt 的代码编译 # workspace # local_repository( name = \u0026#34;apollo\u0026#34;, path = \u0026#34;../apollo\u0026#34;, ) # 添加 apollo 的依赖 load(\u0026#34;@apollo//tools:workspace.bzl\u0026#34;, \u0026#34;apollo_repositories\u0026#34;) apollo_repositories() 报了 -lfastrtps 找不到的问题\n在 cyber rt 的库里加了下 -L\nmonorepo 中编译 # 缺了俩环境变量：\nexport UBUNTU=“2004” export PLATFORM=“X86\u0026#34; "},{"id":11,"href":"/posts/1/01/","title":"2025 01 04 Vim根据模式切换输入法","section":"Blog","content":"参考： macOS下vim 中文输入法切换问题和两种解决方案_mac vim 输入法自动切换-CSDN博客\nvim 安装 smartim 插件\n加入一行到 ~/.vimrc 文件:\nPlugin \u0026#39;ybian/smartim\u0026#39; 运行：:PluginInstall\n修改 ~/.vimrc\n\u0026#34; 设置normal模式切换到的输入法 let g:smartim_default = \u0026#39;com.apple.keylayout.US\u0026#39; 因为习惯 ctrl-c 切换，上面这个只支持 esc 切换。加一下键位映射 \u0026#34; ctrl-c 映射到 esc inoremap \u0026lt;C-c\u0026gt; \u0026lt;esc\u0026gt; "},{"id":12,"href":"/posts/1/01/","title":"2025 01 15 Mutex\u0026cv性能测试","section":"Blog","content":" 参考 # condition_variable 性能测试： 参考：https://www.modernescpp.com/index.php/performancecomparison-of-condition-variables-and-atomics-in-c-20/ 两个线程，ping-pong 互相通知，测试单位时间内的 ping-pong 次数。 测试结果：和 std::condition_variable 性能基本一致 mutex 性能测试： 参考：https://chromium.googlesource.com/external/github.com/abseil/abseil-cpp/+/HEAD/absl/synchronization/mutex_benchmark.cc 测试场景： N 个线程，分别 lock、unlock N 个线程，分别先做一些操作、然后 lock、做一些操作、再 unlock 测试结果：使能优先级继承后，多线程竞争情况下，lock/unlock 性能降低一个数量级左右 备注：也测试了在现有实现下，仅注释掉使能优先级继承的代码，性能恢复到和 std::mutex 一个量级，说明性能下降非代码实现原因，而是优先级继承机制导致。 代码 # #include \u0026lt;condition_variable\u0026gt; #include \u0026lt;mutex\u0026gt; #include \u0026lt;thread\u0026gt; #include \u0026lt;benchmark/benchmark.h\u0026gt; #include \u0026#34;base/synchronization/condition_variable.h\u0026#34; using namespace deeproute::base; template \u0026lt;typename ConditionVariableType\u0026gt; static void BM_PingPong(benchmark::State\u0026amp; state) { ConditionVariableType cv1, cv2; std::mutex mutex; bool data_ready = false; bool should_exit = false; size_t counter = 0; const size_t iterations_per_test = 10000; std::thread pong([\u0026amp;]() { while (!should_exit) { std::unique_lock\u0026lt;std::mutex\u0026gt; lock(mutex); cv2.wait(lock, [\u0026amp;]() { return data_ready || should_exit; }); if (should_exit) break; data_ready = false; cv1.notify_one(); } }); for (auto _ : state) { counter = 0; while (counter \u0026lt; iterations_per_test) { std::unique_lock\u0026lt;std::mutex\u0026gt; lock(mutex); cv1.wait(lock, [\u0026amp;]() { return !data_ready; }); data_ready = true; counter++; cv2.notify_one(); } } { std::lock_guard\u0026lt;std::mutex\u0026gt; lock(mutex); should_exit = true; data_ready = true; } cv2.notify_one(); pong.join(); state.SetItemsProcessed(state.iterations() * iterations_per_test); } BENCHMARK_TEMPLATE(BM_PingPong, std::condition_variable); BENCHMARK_TEMPLATE(BM_PingPong, ConditionVariable); BENCHMARK_MAIN(); "},{"id":13,"href":"/posts/1/01/","title":"出门物品","section":"Blog","content":" 旅行物品清单 # 个人物品 # 护照 / 身份证 机票 / 火车票 / 车票 旅行保险单 钱包 现金 信用卡 / 借记卡 电子产品 # 手机 \u0026amp; 充电器 耳机 \u0026amp; 充电器 电脑 \u0026amp; 充电器 平板 充电宝 相机 转换插头 type c 扩展 衣物 # 上衣 / T 恤 外套 / 风衣 裤子 / 短裤 内衣 / 袜子 运动鞋 卫生用品 # 牙刷 / 牙膏 卫生纸 / 湿巾 剃须刀 护肤品 香水 防晒霜 常用药品 物资 搓澡巾 其他 # 行李锁 雨伞 / 雨衣 垃圾袋 长途 # 拖鞋 眼罩 沙滩鞋 睡衣 帽子 / 墨镜 牙线 "},{"id":14,"href":"/about/","title":"About","section":"Home","content":" 试试 # 测试\n测试一下 # 测试 测试 测试\n测试一下 # 测试 测试 测试 测试 测试 测试 测试\n"},{"id":15,"href":"/posts/1/01/bazel%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95%E8%A6%86%E7%9B%96%E7%8E%87%E6%8A%A5%E5%91%8A/","title":"bazel单元测试覆盖率报告","section":"Blog","content":" 流程 # BUILD file # cc_test( name = \u0026#34;mutex_test\u0026#34;, srcs = [\u0026#34;test_mutex.cpp\u0026#34;], deps = [ \u0026#34;:mutex_lib\u0026#34;, \u0026#34;@gtest//:gtest_main\u0026#34;, \u0026#34;@gtest//:gtest\u0026#34;, ], copts = [\u0026#34;-g\u0026#34;], # Optional: include debug symbols for better coverage report ) 编译运行 # bazel coverage --combined_report=lcov \\ --action_env=COVERAGE_GCOV_OPTIONS=-b \\ --collect_code_coverage \\ --instrument_test_targets \\ --cache_test_results=no \\ --sandbox_writable_path=/ \\ --instrumentation_filter=//src:... \\ //... --combined_report=lcov : 指定生成的覆盖率报告格式为 LCOV，这是一个广泛使用的文本格式，便于进一步处理和可视化。 --action_env=COVERAGE_GCOV_OPTIONS=-b : 设置环境变量 COVERAGE_GCOV_OPTIONS，并传递 -b 选项给 gcov。-b 选项用于告诉 gcov 包含分支信息，有助于生成更详细的覆盖率数据。 --collect_code_coverage : 启用代码覆盖率收集，确保 Bazel 在运行测试时生成必要的覆盖率数据。 --instrument_test_targets : 确保所有测试目标在执行时都被插装，以便收集覆盖率信息。 --cache_test_results=no : 禁用测试结果缓存。这意味着每次运行测试时，Bazel 都会重新执行测试，而不是使用之前的结果。这在调试和覆盖率分析时特别有用。 --sandbox_writable_path=/ : 指定在沙箱中可写的路径。这个选项允许测试在沙箱环境中写入指定的路径，通常用于需要写入文件的测试。 --instrumentation_filter=//src:... : 设定插装过滤器，指示 Bazel 仅对匹配该模式的目标进行插装。在这里，//src:... 表示所有在 src 目录下的目标。可以帮助限制覆盖率分析的范围。 ps: 如果依赖LD_LIBRARY_PATH才能运行，可以通过：--test_env=LD_LIBRARY_PATH=$LD_LIBRARY_PATH 来添加\n生成报告 # # apt update \u0026amp;\u0026amp; apt install -y lcov genhtml --branch-coverage --output report \u0026#34;$(bazel info output_path)/_coverage/_coverage_report.dat\u0026#34; Reference # 单元测试用例依赖外部数据/配置文件 # 当单元测试用例依赖外部数据、配置文件时，需要在cc_test中添加data字段，否则，单元测试过程中会找不到配置文件/数据，如下所示：\ncc_test( name = \u0026#34;safety_test\u0026#34;, srcs = [ \u0026#34;main_test.cpp\u0026#34;, ], deps = [ \u0026#34;:safety_test_lib\u0026#34;, \u0026#34;@gtest//:gtest_main\u0026#34;, ], data = [ \u0026#34;//test/config:test_configs\u0026#34;, \u0026#34;//test/test_data:test_data\u0026#34;, \u0026#34;//config:config_files\u0026#34;, ], visibility = [\u0026#34;//visibility:public\u0026#34;], ) ps:测试用例中数据/配置文件路径需要是从workspace目录开始的绝对路径\n单元测试用例需要写文件 # 如果单元测试过程中，需要在某路径中进行写文件等操作，需要在bazel coverage中添加\u0026ndash;sandbox_writable_path=/，将需要进行写的目录改为可写路径，要不然会报错：error:Read-only file system\n覆盖率报告中不含branches数据 # 生成覆盖率报告的时候，如果报branches\u0026hellip;: no data found，如下所示：\n参考：https://github.com/bazelbuild/bazel/issues/13919\n需要在bazel coverage时添加环境变量\u0026ndash;action_env=COVERAGE_GCOV_OPTIONS=-b启用分支覆盖率：\n"},{"id":16,"href":"/posts/1/01/bazel%E7%BC%96%E8%AF%91go%E9%A1%B9%E7%9B%AE/","title":"bazel编译go项目","section":"Blog","content":" bazel编译项目 # Go相关代码，改bazel编译 # gazelle生成各个BUILD.bazel # 添加gazelle # gazelle是用来自动生成go项目bazel BUILD的工具。 deps.bzl：\nhttp_archive( name = \u0026#34;bazel_gazelle\u0026#34;, integrity = \u0026#34;sha256-12v3pg/YsFBEQJDfooN6Tq+YKeEWVhjuNdzspcvfWNU=\u0026#34;, urls = [ \u0026#34;https://mirror.bazel.build/github.com/bazelbuild/bazel-gazelle/releases/download/v0.37.0/bazel-gazelle-v0.37.0.tar.gz\u0026#34;, \u0026#34;https://github.com/bazelbuild/bazel-gazelle/releases/download/v0.37.0/bazel-gazelle-v0.37.0.tar.gz\u0026#34;, ], ) 总的BUILD中添加： load(\u0026#34;@bazel_gazelle//:def.bzl\u0026#34;, \u0026#34;gazelle\u0026#34;) # gazelle:prefix code.deeproute.ai/cloud-infra/c01-fota gazelle(name = \u0026#34;gazelle\u0026#34;) 添加高版本buildtools # gazelle和bazelbuild/buildtools有冲突，也是版本问题，依赖的buildtools比较新，已有的旧。加了一个新的。\nhttps://github.com/bazelbuild/buildtools/blame/main/build/BUILD.bazel#L11C14-L11C14 运行，生成各个go项目的BUILD # bazel run //:gazelle proto报错 # ERROR: /workspace/monorepo/c01-fota/pkg/os-bridge/BUILD.bazel:18:11: GoCompilePkg pkg/os-bridge/os-bridge.a failed: (Exit 1): builder failed: error executing command bazel-out/k8-opt-exec-2B5CBBC6/bin/external/go_sdk/builder_reset/builder compilepkg -sdk external/go_sdk -installsuffix linux_amd64 -src ... (remaining 69 arguments skipped) Use --sandbox_debug to see verbose messages from the sandbox and retain the sandbox build root for debugging pkg/os-bridge/os-bridge.go:33:33: cannot use \u0026amp;message (value of type *Message) as \u0026#34;code.deeproute.ai/cloud-infra/c01-fota/vendor/google.golang.org/protobuf/reflect/protoreflect\u0026#34;.ProtoMessage value in argument to proto.Marshal: *Message does not implement \u0026#34;code.deeproute.ai/cloud-infra/c01-fota/vendor/google.golang.org/protobuf/reflect/protoreflect\u0026#34;.ProtoMessage (wrong type for method ProtoReflect) have ProtoReflect() \u0026#34;google.golang.org/protobuf/reflect/protoreflect\u0026#34;.Message want ProtoReflect() \u0026#34;code.deeproute.ai/cloud-infra/c01-fota/vendor/google.golang.org/protobuf/reflect/protoreflect\u0026#34;.Message pkg/os-bridge/os-bridge.go:46:32: cannot use \u0026amp;message (value of type *Message) as \u0026#34;code.deeproute.ai/cloud-infra/c01-fota/vendor/google.golang.org/protobuf/reflect/protoreflect\u0026#34;.ProtoMessage value in argument to proto.Marshal: *Message does not implement \u0026#34;code.deeproute.ai/cloud-infra/c01-fota/vendor/google.golang.org/protobuf/reflect/protoreflect\u0026#34;.ProtoMessage (wrong type for method ProtoReflect) have ProtoReflect() \u0026#34;google.golang.org/protobuf/reflect/protoreflect\u0026#34;.Message want ProtoReflect() \u0026#34;code.deeproute.ai/cloud-infra/c01-fota/vendor/google.golang.org/protobuf/reflect/protoreflect\u0026#34;.Message pkg/os-bridge/os-bridge.go:82:33: cannot use \u0026amp;message (value of type *Message) as \u0026#34;code.deeproute.ai/cloud-infra/c01-fota/vendor/google.golang.org/protobuf/reflect/protoreflect\u0026#34;.ProtoMessage value in argument to proto.Marshal: *Message does not implement \u0026#34;code.deeproute.ai/cloud-infra/c01-fota/vendor/google.golang.org/protobuf/reflect/protoreflect\u0026#34;.ProtoMessage (wrong type for method ProtoReflect) have ProtoReflect() \u0026#34;google.golang.org/protobuf/reflect/protoreflect\u0026#34;.Message want ProtoReflect() \u0026#34;code.deeproute.ai/cloud-infra/c01-fota/vendor/google.golang.org/protobuf/reflect/protoreflect\u0026#34;.Message compilepkg: error running subcommand PATH=/usr/bin:/bin \\ GOEXPERIMENT=nocoverageredesign \\ CGO_ENABLED=1 \\ GOARCH=amd64 \\ GOPATH= \\ GOOS=linux \\ GOROOT=bazel-out/k8-fastbuild-ST-b33d65c724e6/bin/external/io_bazel_rules_go/stdlib_ \\ TMPDIR=/tmp \\ GOTOOLCHAIN=local \\ GOROOT_FINAL=GOROOT \\ external/go_sdk/pkg/tool/linux_amd64/compile -p code.deeproute.ai/cloud-infra/c01-fota/pkg/os-bridge -importcfg /home/jiaqili/.cache/bazel/_bazel_jiaqili/3f5ca13afad49559f8f755414e5ed340/sandbox/linux-sandbox/485/execroot/c01_fota/bazel-out/k8-fastbuild/bin/pkg/os-bridge/importcfg1326253688 -pack -trimpath=/home/jiaqili/.cache/bazel/_bazel_jiaqili/3f5ca13afad49559f8f755414e5ed340/sandbox/linux-sandbox/485/execroot/c01_fota -o /home/jiaqili/.cache/bazel/_bazel_jiaqili/3f5ca13afad49559f8f755414e5ed340/sandbox/linux-sandbox/485/execroot/c01_fota/bazel-out/k8-fastbuild/bin/pkg/os-bridge/os-bridge.x -linkobj /home/jiaqili/.cache/bazel/_bazel_jiaqili/3f5ca13afad49559f8f755414e5ed340/sandbox/linux-sandbox/485/execroot/c01_fota/bazel-out/k8-fastbuild/bin/pkg/os-bridge/os-bridge.a -- /home/jiaqili/.cache/bazel/_bazel_jiaqili/3f5ca13afad49559f8f755414e5ed340/sandbox/linux-sandbox/485/execroot/c01_fota/bazel-out/k8-fastbuild/bin/pkg/os-bridge/bridge_go_proto_/code.deeproute.ai/cloud-infra/c01-fota/pkg/os-bridge/os-bridge.pb.go /home/jiaqili/.cache/bazel/_bazel_jiaqili/3f5ca13afad49559f8f755414e5ed340/sandbox/linux-sandbox/485/execroot/c01_fota/pkg/os-bridge/os-bridge.go: exit status 2 Target //:c01-fota failed to build Use --verbose_failures to see the command lines of failed build steps. INFO: Elapsed time: 5.609s, Critical Path: 2.80s INFO: 6 processes: 4 internal, 2 linux-sandbox. FAILED: Build did NOT complete successfully 有已经生成好了的pb.go，先直接用了，能编过。 需要加：\n\u0026#34;//vendor/google.golang.org/protobuf/reflect/protoreflect\u0026#34;, \u0026#34;//vendor/google.golang.org/protobuf/runtime/protoimpl\u0026#34;, 配置gazelle，不通过proto生成pb.go，直接使用已生成的proto # gazelle上添加：# gazelle:proto disable_global\n# gazelle:prefix code.deeproute.ai/cloud-infra/c01-fota # gazelle:proto disable_global gazelle(name = \u0026#34;gazelle\u0026#34;) 参考：https://github.com/bazel-contrib/rules_go/blob/master/proto/core.rst#option-2-use-pre-generated-pbgo-files gazelle\nhttp_archive( name = \u0026#34;bazel_gazelle\u0026#34;, integrity = \u0026#34;sha256-12v3pg/YsFBEQJDfooN6Tq+YKeEWVhjuNdzspcvfWNU=\u0026#34;, urls = [ \u0026#34;https://mirror.bazel.build/github.com/bazelbuild/bazel-gazelle/releases/download/v0.37.0/bazel-gazelle-v0.37.0.tar.gz\u0026#34;, \u0026#34;https://github.com/bazelbuild/bazel-gazelle/releases/download/v0.37.0/bazel-gazelle-v0.37.0.tar.gz\u0026#34;, ], ) # 安装go # apt安装 # sudo apt install golang\ntar包安装 # https://go.dev/dl/\nhttps://go.dev/doc/install\nwget https://go.dev/dl/go1.23.2.linux-arm64.tar.gz rm -rf /usr/local/go \u0026amp;\u0026amp; tar -C /usr/local -xzf go1.23.2.linux-arm64.tar.gz "},{"id":17,"href":"/posts/1/01/c-%E6%A8%A1%E6%9D%BF%E5%88%86%E4%BA%AB/","title":"c++模板分享","section":"Blog","content":"c++templates基础 - 20240118.pptx\n为什么需要模版 # Bad Old Days # Reuse with cut-N-paste # struct int_node { int_node* next; int value; }; struct int_list { int_node* front; int_node* back; }; void int_list_append(int_list* l, int val); void int_list_prepend(int_list* l, int val); void int_list_clear(int_list* l); struct double_node { double_node* next; double value; }; struct double_list { double_node* front; double_node* back; }; double dbl_list_append(int_list* l, double val); void dbl_list_prepend(int_list* l, double val); void dbl_list_clear(int_list* l); Reuse with Type Erasure # #include \u0026lt;stdlib.h\u0026gt; void qsort(void *base, size_t nmemb, size_t size, int (*compare)(const void *, const void *)); int cmp_dbl(const void* va, const void* vb) { double a = *((double const*) va); double b = *((double const*) vb); if (a \u0026lt; b) return -1; else if (a == b) return 0; else return 1; } void f() { double dbl_data[4] = { 3.14159, 1.41421, 2.71828, 1.61803 }; qsort(\u0026amp;dbl_data[0], 4u, sizeof(double), \u0026amp;cmp_dbl); } Reuse with Macros # #define BUILD_COMPARE(TYPE) \\ int cmp_ ## TYPE(const void* va, const void* vb) \\ { \\ TYPE const* pa = static_cast\u0026lt;TYPE const*\u0026gt;(va); \\ TYPE const* pb = static_cast\u0026lt;TYPE const*\u0026gt;(vb); \\ if (*pa \u0026lt; *pb) return -1; \\ else if (*pa == *pb) return 0; \\ else return 1; \\ } BUILD_COMPARE(float) BUILD_COMPARE(double) void h() { float data[4] = { 4.0, 3.0, 2.0, 1.0 }; qsort(\u0026amp;data[0], 4u, sizeof(float), \u0026amp;cmp_float); //- OK qsort(\u0026amp;data[0], 4u, sizeof(float), \u0026amp;cmp_dbl); //- Error } Code Reuse # These problems have been around a long time In the 1970\u0026rsquo;s, some languages began allowing algorithms to be written in terms of types to-be-specified-later Algorithms were then instantiated on demand using type arguments This approach is now known as generic programming: ****\tC++ supports generic programming with templates 模版基础 # 分类 # thing template # This kind of template \u0026hellip; is a parametrized description of a family of \u0026hellip;\nFunction Template (c++ 98/03) Class Template (c++ 98/03) Member Function Template (c++ 98/03) Alias Template (c++11) Variable Template (c++14) lambda Template (c++20) template parameter # Type template parameters Non-type template parameters (NTTPs) Template template parameters 模版基本用法 # Function Template # Function template_ is a parametrized description of a family of _functions\nClass Template # Alias Template # Policy based design # 参考材料 # Back to Basics: Templates - Bob Steagall - CppCon 2021 # https://www.youtube.com/watch?v=XN319NYEOcE\nhttps://www.youtube.com/watch?v=2Y9XbltAfXs\nback_to_basics_templates_part_1__bob_steagall__cppcon_2021.pdf\nback_to_basics_templates_part_2__bob_steagall__cppcon_2021.pdf\nBack to Basics: Templates in C++ - Nicolai Josuttis - CppCon 2022 # https://www.youtube.com/watch?v=HqsEHG0QJXU\nCTemplates_cppcon_220918.pdf\nhttps://zhuanlan.zhihu.com/p/378360055\nC++模板元编程实战 一个深度学习框架的初步实现 (李伟) (Z-Library).pdf\n"},{"id":18,"href":"/contact/","title":"Contact","section":"Home","content":" e-mail: ljq0831@qq.com github: https://github.com/manchey "},{"id":19,"href":"/posts/1/01/cursor%E4%BF%AEmachine-id/","title":"cursor修machine id","section":"Blog","content":" 手动配置方法 # 完全关闭 Cursor\n找到配置文件位置：\nWindows: %APPDATA%\\Cursor\\User\\globalStorage\\storage.json macOS: ~/Library/Application\\ Support/Cursor/User/globalStorage/storage.json Linux: ~/.config/Cursor/User/globalStorage/storage.json 备份 storage.json\n编辑 storage.json 并更新以下字段（使用新的随机UUID）：\n{ \u0026#34;telemetry.machineId\u0026#34;: \u0026#34;生成新的uuid\u0026#34;, \u0026#34;telemetry.macMachineId\u0026#34;: \u0026#34;生成新的uuid\u0026#34;, \u0026#34;telemetry.devDeviceId\u0026#34;: \u0026#34;生成新的uuid\u0026#34;, \u0026#34;telemetry.sqmId\u0026#34;: \u0026#34;生成新的uuid\u0026#34;, \u0026#34;lastModified\u0026#34;: \u0026#34;2024-01-01T00:00:00.000Z\u0026#34;, \u0026#34;version\u0026#34;: \u0026#34;1.0.1\u0026#34; } 保存文件并重启 Cursor "},{"id":20,"href":"/posts/1/01/docker%E5%91%BD%E4%BB%A4/","title":"docker命令","section":"Blog","content":" 查看具体镜像和容器占用的空间 # # 查看所有镜像的大小 docker images # 查看所有容器的大小 docker ps -a --size 查看 Docker 系统信息 # docker system df 这个命令会显示：\n镜像的总数和占用的空间 容器的总数和占用的空间 卷的总数和占用的空间 清理构建缓存 # docker builder prune "},{"id":21,"href":"/posts/1/01/mac%E4%B8%ADvscode%E6%89%93%E5%BC%80devdocker%E6%8F%90%E7%A4%BAremote-extension-host-terminated-unexpectedly/","title":"mac中vscode打开devdocker提示\"Remote Extension host terminated unexpectedly\"","section":"Blog","content":" 参考 # https://github.com/microsoft/vscode-remote-release/issues/8967#issuecomment-1873199481\nswitched from VirtioFS to gRPC FUSE and disabled \u0026lsquo;Use Virtualization Framework\u0026rsquo; in my Docker Desktop settings\n"},{"id":22,"href":"/posts/1/01/mac%E8%B0%83%E7%94%A8docker%E4%B8%AD%E7%9A%84gui%E7%95%8C%E9%9D%A2/","title":"mac调用docker中的GUI界面","section":"Blog","content":" mac上，使用docker中的gui程序 # 安装XQuartz，通过XQuartz打开terminal，启动docker docker里设置环境变量：export DISPLAY=\u0026lt;IP\u0026gt;:0 主机： xhost + \u0026lt;IP\u0026gt; Reference： https://shaoguangleo.github.io/2018/01/21/docker-run-gui-on-macosx/ https://zhuanlan.zhihu.com/p/652143343 "},{"id":23,"href":"/posts/1/01/mediapipe%E5%A6%82%E4%BD%95%E8%BF%90%E8%BD%AC/","title":"Mediapipe如何运转","section":"Blog","content":" Mediapipe 的版本 # 0.8.0\nMediapipe 的基本概念 # 参考：2024-06-17-Mediapipe调研\nMediapipe 有几个线程？ # 编译了 example 的 hello world，发现只有两类线程：\n主线程，main 函数的线程，这个不用说了 Executor 线程，Mediapipe 默认只有一个 Executtor：ThreadPoolExecutor #include \u0026#34;mediapipe/framework/calculator_graph.h\u0026#34; #include \u0026#34;mediapipe/framework/port/logging.h\u0026#34; #include \u0026#34;mediapipe/framework/port/parse_text_proto.h\u0026#34; #include \u0026#34;mediapipe/framework/port/status.h\u0026#34; namespace mediapipe { ::mediapipe::Status PrintHelloWorld() { // Configures a simple graph, which concatenates 2 PassThroughCalculators. CalculatorGraphConfig config = ParseTextProtoOrDie\u0026lt;CalculatorGraphConfig\u0026gt;(R\u0026#34;( input_stream: \u0026#34;in\u0026#34; output_stream: \u0026#34;out\u0026#34; node { calculator: \u0026#34;PassThroughCalculator\u0026#34; input_stream: \u0026#34;in\u0026#34; output_stream: \u0026#34;out1\u0026#34; } node { calculator: \u0026#34;PassThroughCalculator\u0026#34; input_stream: \u0026#34;out1\u0026#34; output_stream: \u0026#34;out\u0026#34; } )\u0026#34;); CalculatorGraph graph; MP_RETURN_IF_ERROR(graph.Initialize(config)); ASSIGN_OR_RETURN(OutputStreamPoller poller, graph.AddOutputStreamPoller(\u0026#34;out\u0026#34;)); MP_RETURN_IF_ERROR(graph.StartRun({})); // Give 10 input packets that contains the same std::string \u0026#34;Hello World!\u0026#34;. for (int i = 0; i \u0026lt; 100; ++i) { MP_RETURN_IF_ERROR(graph.AddPacketToInputStream( \u0026#34;in\u0026#34;, MakePacket\u0026lt;std::string\u0026gt;(\u0026#34;Hello World!\u0026#34;).At(Timestamp(i)))); sleep(3); } // Close the input stream \u0026#34;in\u0026#34;. MP_RETURN_IF_ERROR(graph.CloseInputStream(\u0026#34;in\u0026#34;)); mediapipe::Packet packet; // Get the output packets std::string. while (poller.Next(\u0026amp;packet)) { std::cout \u0026lt;\u0026lt; \u0026#34;Test: \u0026#34; \u0026lt;\u0026lt; std::endl; LOG(ERROR) \u0026lt;\u0026lt; packet.Get\u0026lt;std::string\u0026gt;(); } return graph.WaitUntilDone(); } } // namespace mediapipe int main(int argc, char** argv) { std::cout \u0026lt;\u0026lt; \u0026#34;main: \u0026#34; \u0026lt;\u0026lt; std::endl; google::InitGoogleLogging(argv[0]); CHECK(mediapipe::PrintHelloWorld().ok()); return 0; } ThreadPoolExecutor 的实现 # 它就是一个简单的 ThreadPool，提供一个 Schedule 的函数用于提交 task，内部有一个 tasks 的队列，Schedule 将 task 放入 tasks 的队列，ThreadPool 内部可以有多个 WorkerThread，从 tasks 队列中取任务（tasks 有锁保护）。\nExecutor 对外的接口是 AddTask，它会调用 Schedule 函数，所以新增自定义 Executor 就是重写 Schedule 函数。\nScheduler 中会调用 AddTask（严格来说是 ScheduleQueue）\nclass Executor { public: virtual ~Executor(); // A registered Executor subclass must implement the static factory method // Create. The Executor subclass cannot be registered without it. // // static ::mediapipe::StatusOr\u0026lt;Executor*\u0026gt; Create( // const MediaPipeOptions\u0026amp; extendable_options); // // Create validates extendable_options, then calls the constructor, and // returns the newly allocated Executor object. // The scheduler queue calls this method to tell the executor that it has // a new task to run. The executor should use its execution mechanism to // invoke task_queue-\u0026gt;RunNextTask. virtual void AddTask(TaskQueue* task_queue) { Schedule([task_queue] { task_queue-\u0026gt;RunNextTask(); }); } // Schedule the specified \u0026#34;task\u0026#34; for execution in this executor. virtual void Schedule(std::function\u0026lt;void()\u0026gt; task) = 0; }; CalculatorGraph 有哪些成员变量？ # 关键成员变量：\nstd::unique_ptr validated_graph_;，会将输入的 graph config 转成这种 validated graph，ValidatedGraphConfig 是一个 class graph 的重要组成元素：\n基本下面三个成员就储存了整个 graph 的信息，CalculatorNode 是 graph 的点，input 和 output 是边，尤其是 OutputStreamManager 里面存储了 output stream 对应的 input stream 是哪些：\nstd::unique_ptr\u0026lt;InputStreamManager[]\u0026gt; input_stream_managers_; std::unique_ptr\u0026lt;OutputStreamManager[]\u0026gt; output_stream_managers_; std::unique_ptr\u0026lt;absl::FixedArray\u0026gt; nodes_; Scheduler 和 Executor：\nstd::map\u0026lt;std::string, std::shared_ptr\u0026gt; executors_;，这里可以有很多个 Executor，key 是 Executor 的 name internal::Scheduler scheduler_;，这里还有一个 Scheduler，它也是运转的关键 // True if the graph was initialized. bool initialized_ = false; // A packet type that has SetAny() called on it. PacketType any_packet_type_; // The ValidatedGraphConfig object defining this CalculatorGraph. std::unique_ptr\u0026lt;ValidatedGraphConfig\u0026gt; validated_graph_; // The PacketGeneratorGraph to use to generate all the input side packets. PacketGeneratorGraph packet_generator_graph_; // True if the graph has source nodes. bool has_sources_ = false; // A flat array of InputStreamManager/OutputStreamManager/ // OutputSidePacketImpl/CalculatorNode corresponding to the input/output // stream indexes, output side packet indexes, and calculator indexes // respectively in validated_graph_. // Once allocated these structures must not be reallocated since // internal structures may point to individual entries in the array. std::unique_ptr\u0026lt;InputStreamManager[]\u0026gt; input_stream_managers_; std::unique_ptr\u0026lt;OutputStreamManager[]\u0026gt; output_stream_managers_; std::unique_ptr\u0026lt;OutputSidePacketImpl[]\u0026gt; output_side_packets_; std::unique_ptr\u0026lt;absl::FixedArray\u0026lt;CalculatorNode\u0026gt;\u0026gt; nodes_; // The graph output streams. std::vector\u0026lt;std::shared_ptr\u0026lt;internal::GraphOutputStream\u0026gt;\u0026gt; graph_output_streams_; // Maximum queue size for an input stream. This is used by the scheduler to // restrict memory usage. int max_queue_size_ = -1; // Mode for adding packets to a graph input stream. Set to block until all // affected input streams are not full by default. GraphInputStreamAddMode graph_input_stream_add_mode_ ABSL_GUARDED_BY(full_input_streams_mutex_); // For a source node or graph input stream (specified using id), // this stores the set of dependent input streams that have hit their // maximum capacity. Graph input streams are also treated as nodes. // A node is scheduled only if this set is empty. Similarly, a packet // is added to a graph input stream only if this set is empty. // Note that this vector contains an unused entry for each non-source node. std::vector\u0026lt;absl::flat_hash_set\u0026lt;InputStreamManager*\u0026gt;\u0026gt; full_input_streams_ ABSL_GUARDED_BY(full_input_streams_mutex_); // Maps stream names to graph input stream objects. absl::flat_hash_map\u0026lt;std::string, std::unique_ptr\u0026lt;GraphInputStream\u0026gt;\u0026gt; graph_input_streams_; // Maps graph input streams to their virtual node ids. absl::flat_hash_map\u0026lt;std::string, int\u0026gt; graph_input_stream_node_ids_; // Maps graph input streams to their max queue size. absl::flat_hash_map\u0026lt;std::string, int\u0026gt; graph_input_stream_max_queue_size_; // The factory for making counters associated with this graph. std::unique_ptr\u0026lt;CounterFactory\u0026gt; counter_factory_; // Executors for the scheduler, keyed by the executor\u0026#39;s name. The default // executor\u0026#39;s name is the empty std::string. std::map\u0026lt;std::string, std::shared_ptr\u0026lt;Executor\u0026gt;\u0026gt; executors_; // The processed input side packet map for this run. std::map\u0026lt;std::string, Packet\u0026gt; current_run_side_packets_; std::map\u0026lt;std::string, Packet\u0026gt; service_packets_; // Vector of errors encountered while running graph. Always use RecordError() // to add an error to this vector. std::vector\u0026lt;::mediapipe::Status\u0026gt; errors_ ABSL_GUARDED_BY(error_mutex_); // True if the default executor uses the application thread. bool use_application_thread_ = false; // Condition variable that waits until all input streams that depend on a // graph input stream are below the maximum queue size. absl::CondVar wait_to_add_packet_cond_var_ ABSL_GUARDED_BY(full_input_streams_mutex_); // Mutex for the vector of errors. absl::Mutex error_mutex_; // Status variable to indicate if the graph has encountered an error. std::atomic\u0026lt;bool\u0026gt; has_error_; // Mutex for full_input_streams_. mutable absl::Mutex full_input_streams_mutex_; // Number of closed graph input streams. This is a separate variable because // it is not safe to hold a lock on the scheduler while calling Close() on an // input stream. Hence, we decouple the closing of the stream and checking its // status. // TODO: update this comment. std::atomic\u0026lt;unsigned int\u0026gt; num_closed_graph_input_streams_; // The graph tracing and profiling interface. It is owned by the // CalculatorGraph using a shared_ptr in order to allow threadsafe access // to the ProfilingContext from clients that may outlive the CalculatorGraph // such as GlContext. It is declared here before the Scheduler so that it // remains available during the Scheduler destructor. std::shared_ptr\u0026lt;ProfilingContext\u0026gt; profiler_; internal::Scheduler scheduler_; Scheduler 和 Executor 的关系是？ # 下面是 Scheduler 的成员变量，关键的变量：\nCalculatorGraph* graph_;，graph 和 Scheduler 的关系是你中有我、我中有你，所以实际它俩是作为一个 bazel target 来编译的（不这样也编译不过，它俩影响了环形依赖） SchedulerQueue default_queue_;，默认调度队列，如果使用的默认的 ThreadPoolExecutor，那就用这个队列，Scheduler 会从这个队列中取 task，将其提交给 ThreadPoolExecutor std::map\u0026lt;std::string, std::unique_ptr\u0026gt; non_default_queues_;，如果有注册新的 Executor，那么每个 Executor 对应一个调度队列，key 是 Executor name // The calculator graph to run. CalculatorGraph* graph_; // Data accessed by all SchedulerQueues. SchedulerShared shared_; // Queue of nodes that need to be run. SchedulerQueue default_queue_; // Non-default scheduler queues, keyed by their executor names. std::map\u0026lt;std::string, std::unique_ptr\u0026lt;SchedulerQueue\u0026gt;\u0026gt; non_default_queues_; // Holds pointers to all queues used by the scheduler, for convenience. std::vector\u0026lt;SchedulerQueue*\u0026gt; scheduler_queues_; // Priority queue of source nodes ordered by layer and then source process // order. This stores the set of sources that are yet to be run. std::priority_queue\u0026lt;SchedulerQueue::Item\u0026gt; sources_queue_ ABSL_GUARDED_BY(state_mutex_); // Source nodes with the smallest source layer are at the beginning of // unopened_sources_. Before the scheduler is started, all source nodes are // added to unopened_sources_. Once the scheduler starts running, // unopened_sources_ should only be accessed under the protection of // state_mutex_. A source node is removed from unopened_sources_ after it is // opened. std::set\u0026lt;CalculatorNode*, SourceLayerCompare\u0026gt; unopened_sources_; // Keeps track of sources that can be considered for scheduling. Sources are // scheduled in layers, and those that are not currently active will not be // scheduled even if ready. Sources are removed once they are closed. std::vector\u0026lt;CalculatorNode*\u0026gt; active_sources_; // Condition variable used to wait for some changes to the scheduler state. // These correspond to the Wait* methods in this class. // Not all state changes need to signal this, only those that enter one of // the waitable states. absl::CondVar state_cond_var_ ABSL_GUARDED_BY(state_mutex_); // Number of queues which are not idle. // Note: this indicates two slightly different things: // a. the number of queues which still have nodes running; // b. the number of queues whose executors may still access the scheduler. // When a queue becomes idle, it has stopped running nodes, and the scheduler // decrements the count. However, it is not done accessing the scheduler // until HandleIdle returns. Therefore, a and b are briefly out of sync. // This is ok, because it happens within a single critical section, which is // guarded by state_mutex_. If we wanted to split this critical section, we // would have to separate a and b into two variables. int non_idle_queue_count_ ABSL_GUARDED_BY(state_mutex_) = 0; // Tasks to be executed on the application thread. std::deque\u0026lt;std::function\u0026lt;void()\u0026gt;\u0026gt; app_thread_tasks_ ABSL_GUARDED_BY(state_mutex_); // Used by HandleIdle to avoid multiple concurrent executions. // We cannot simply hold a mutex throughout it, for two reasons: // - We need it to be reentrant, which Mutex does not support. // - We want simultaneous calls to return immediately instead of waiting, // and Mutex\u0026#39;s TryLock is not guaranteed to work. bool handling_idle_ ABSL_GUARDED_BY(state_mutex_) = false; // Mutex for the scheduler state and related things. // Note: state_ is declared as atomic so that its getter methods don\u0026#39;t need // to acquire state_mutex_. absl::Mutex state_mutex_; // Current state of the scheduler. std::atomic\u0026lt;State\u0026gt; state_ = ATOMIC_VAR_INIT(STATE_NOT_STARTED); // True if all graph input streams are closed. bool graph_input_streams_closed_ ABSL_GUARDED_BY(state_mutex_) = false; // Number of throttled graph input streams. int throttled_graph_input_stream_count_ ABSL_GUARDED_BY(state_mutex_) = 0; // Used to stop WaitUntilGraphInputStreamUnthrottled. int unthrottle_seq_num_ ABSL_GUARDED_BY(state_mutex_) = 0; // Used to stop WaitForObservedOutput. bool observed_output_signal_ ABSL_GUARDED_BY(state_mutex_) = false; // True if an application thread is waiting in WaitForObservedOutput. bool waiting_for_observed_output_ ABSL_GUARDED_BY(state_mutex_) = false; graph 是如何开始运转的？ # 有两种方式：\n一种是调用 graph.AddPacketToInputStream，给 graph 灌入数据，然后 graph 开始执行 一种是 Source Node，没有 input，有 output，它会产生数据，让 graph 运转起来 graph.AddPacketToInputStream # 关键的函数：\n// InputStreamManager is thread safe. GraphInputStream is not, so this method // should not be called by multiple threads concurrently. Note that this could // potentially lead to the max queue size being exceeded by one packet at most // because we don\u0026#39;t have the lock over the input stream. (*stream)-\u0026gt;AddPacket(std::forward\u0026lt;T\u0026gt;(packet)); if (has_error_) { ::mediapipe::Status error_status; GetCombinedErrors(\u0026#34;Graph has errors: \u0026#34;, \u0026amp;error_status); return error_status; } (*stream)-\u0026gt;PropagateUpdatesToMirrors(); VLOG(2) \u0026lt;\u0026lt; \u0026#34;Packet added directly to: \u0026#34; \u0026lt;\u0026lt; stream_name; // Note: one reason why we need to call the scheduler here is that we have // re-throttled the graph input streams, and we may need to unthrottle them // again if the graph is still idle. Unthrottling basically only lets in one // packet at a time. TODO: add test. scheduler_.AddedPacketToGraphInputStream(); stream，它是从 graph_input_streams_ 中查找出来的 (*stream)-\u0026gt;AddPacket(std::forward(packet));，将 packet 放入队列，实际是直接放入了 OutputStreamHandler 的队列，就好像有一个透明的 Calculator 一样 (*stream)-\u0026gt;PropagateUpdatesToMirrors(); void CalculatorGraph::GraphInputStream::PropagateUpdatesToMirrors() { // Since GraphInputStream doesn\u0026#39;t allow SetOffset() and // SetNextTimestampBound(), the timestamp bound to propagate is only // determined by the timestamp of the output packets. CHECK(!shard_.IsEmpty()) \u0026lt;\u0026lt; \u0026#34;Shard with name \\\u0026#34;\u0026#34; \u0026lt;\u0026lt; manager_-\u0026gt;Name() \u0026lt;\u0026lt; \u0026#34;\\\u0026#34; failed\u0026#34;; manager_-\u0026gt;PropagateUpdatesToMirrors( shard_.LastAddedPacketTimestamp().NextAllowedInStream(), \u0026amp;shard_); } manager_ 实际是一个 OutputStreamManager，它的 PropagateUpdatesToMirrors 实际上会将 OutputStreamShard 的 packets 取出来，放到 mirror 中保存的 InputStreamHandler 中\nSource Node # 待查看\nInputStreamHandler、OutputStreamHandler、OutputStreamManager、InputStreamManager 的作用是？ # 两个 Calculator 是通过 stream 进行“链接”，分为：InputStream 和 OutputStream。\nInputStreamHandler 有一个功能就是判断 Calculator 是否 Ready，Ready 的话就可以将 Calculator 放入 ScheduleQueue，它类的解释：\n它内部包含了一个 InputStreamManager Set，看起来像是从 CalculatorGraph 的成员变量赋值过来的，给过来的是一个指针的 Set\nInputStreamManager 的类解释：\nOutputStreamHandler：\n它里面也是包含了一个 OutputStreamManager Set，看起来也是从 CalculatorGraph 的成员变量赋值过来的：\nOutputStreamManager：\nCalculatorNode 和 Calculator 是什么关系？ # 从 CalculatorGraph 的成员变量看，它是存储的 CalculatorNode，Scheduler 调度的时候也是调度的 CalculatorNode，那么它和 Calculator 的关系是？\n看一下 CalculatorNode 的成员变量，关键的变量：\nstd::unique_ptr calculator_;——它会包含 Calculator 的 unique_ptr CalculatorContextManager calculator_context_manager_;——这里实际是获取 Calculator 的 Context std::unique_ptr input_stream_handler_;——管理 input stream std::unique_ptr output_stream_handler_;——管理 output stream internal::SchedulerQueue* scheduler_queue_ = nullptr;——CalculatorNode 所在的调度队列 // The calculator. std::unique_ptr\u0026lt;CalculatorBase\u0026gt; calculator_; // Keeps data which a Calculator subclass needs access to. std::unique_ptr\u0026lt;CalculatorState\u0026gt; calculator_state_; int node_id_ = -1; std::string name_; // Optional user-defined name // Name of the executor which the node will execute on. If empty, the node // will execute on the default executor. std::string executor_; // The layer a source calculator operates on. int source_layer_ = 0; // The status of the current Calculator that this CalculatorNode // is wrapping. kStateActive is currently used only for source nodes. enum NodeStatus { kStateUninitialized = 0, kStatePrepared = 1, kStateOpened = 2, kStateActive = 3, kStateClosed = 4 }; NodeStatus status_ ABSL_GUARDED_BY(status_mutex_){kStateUninitialized}; // The max number of invocations that can be scheduled in parallel. int max_in_flight_ = 1; // The following two variables are used for the concurrency control of node // scheduling. // // The number of invocations that are scheduled but not finished. int current_in_flight_ ABSL_GUARDED_BY(status_mutex_) = 0; // SchedulingState incidates the current state of the node scheduling process. // There are four possible transitions: // (a) From kIdle to kScheduling. // Any thread that makes this transition becomes the scheduling thread and // will be responsible for preparing and scheduling all possible invocations. // (b) From kScheduling to kSchedulingPending. // Any thread, except the scheduling thread, can make this transition. // kSchedulingPending indicates that some recent changes require the // scheduling thread to recheck the node readiness after current scheduling // iteration. // (c) From kSchedulingPending to kScheduling. // Made by the scheduling thread to indicate that it has already caught up // with all the recent changes that can affect node readiness. // (d) From kScheduling to kIdle. Made by the scheduling thread when there is // no more scheduling work to be done. enum SchedulingState { kIdle = 0, // kScheduling = 1, // kSchedulingPending = 2 }; SchedulingState scheduling_state_ ABSL_GUARDED_BY(status_mutex_) = kIdle; std::function\u0026lt;void()\u0026gt; ready_for_open_callback_; std::function\u0026lt;void()\u0026gt; source_node_opened_callback_; bool input_stream_headers_ready_called_ ABSL_GUARDED_BY(status_mutex_) = false; bool input_side_packets_ready_called_ ABSL_GUARDED_BY(status_mutex_) = false; bool input_stream_headers_ready_ ABSL_GUARDED_BY(status_mutex_) = false; bool input_side_packets_ready_ ABSL_GUARDED_BY(status_mutex_) = false; // Owns and manages all CalculatorContext objects. CalculatorContextManager calculator_context_manager_; std::shared_ptr\u0026lt;ProfilingContext\u0026gt; profiling_context_; // Mutex for node status. mutable absl::Mutex status_mutex_; // Manages the set of input side packets. InputSidePacketHandler input_side_packet_handler_; // Collection of all OutputSidePacket objects. std::unique_ptr\u0026lt;OutputSidePacketSet\u0026gt; output_side_packets_; std::unique_ptr\u0026lt;InputStreamHandler\u0026gt; input_stream_handler_; std::unique_ptr\u0026lt;OutputStreamHandler\u0026gt; output_stream_handler_; // Whether this is a GPU calculator. bool uses_gpu_ = false; // True if CleanupAfterRun() needs to call CloseNode(). bool needs_to_close_ = false; internal::SchedulerQueue* scheduler_queue_ = nullptr; const ValidatedGraphConfig* validated_graph_ = nullptr; 在 CalculatorGraph 初始化的时候，会创建一个 CalculatorNode 的集合，每个 Node 会调用一下初始化函数，初始化时，会将 input_stream_managers_ 和 output_stream_managers_ 传递进去，在 CalculatorNode::Initialize 函数中初始化了 inputstream 和 outputstream 的：\n而在 CalculatorNode::PrepareForRun 再创建的 Calculator 的 uniuqe_ptr。\nCalculator 的 Output 是如何到达 OutputStreamHandler 的？ # CalculatorContext 的 Outputs 接口定义：OutputStreamShardSet\u0026amp; Outputs();，它返回的是一个 OutputStreamShardSet，返回的是 CalculatorContext 内部的 outputs_：\n它是外部传进来的：\nCalculatorContext 是什么时期创建的？\nCalculatorContext 是由 CalculatorContextManager 管理的（默认是一对一），而每个 CalculatorNode 有一个自己的 CalculatorContextManager，它在 CalculatorNode 构造时构造的，在 CalculatorNode 初始化时，将 input stream 和 output stream 赋值到了 CalculatorContextManager 中。\n但是 CalculatorContext 中存的只是 OutputStreamShard，它和 OutputStreamHandler 是什么关系？\n在 CalculatorNode::ProcessNode 函数中，执行了 Calculator 的 Process 函数，之后会调用一下 output_stream_handler 的 PostProcess 函数，至此终于将 Calculator 的 Output 和 OutputStreamHandler 关联上了：\n上一个 Calculator 的 Output 是怎么传递到下一个 Calculator 的 Input？ # 关键还是上面的 OutputStreamHandler 的 PostProcess：它里面调用了 OutputStreamManager 的 PropagateUpdatesToMirrors，这个函数内部会将 packets 转给对应的 input_stream_handler：\n经过几处辗转，调用了 InputStreamHandler::ScheduleInvocations，它会判断 node_readiness = GetNodeReadiness 是否 Ready：\n如果 Ready 的话，就会调用 FillInputSet，将存储在 InputStreamManager 中的 Packet 填入到 Calculator 的 InputStreamShard：\n什么时刻判断下一个 Node 是否 Ready？如何放到 ScheduleQueue 中的？ # 接上文，在 input_stream_handler 的 MovePackets 和 AddPackets 都会判断一下是否 Ready，具体是下面的 notification_()：\n在 CalculatorGraph::PrepareForRun 函数中，调用了 Node 的 PrepareForRun 函数：\nNode 的 PrepareForRun 函数中给 input_stream_handler 注册了 notification 的回调函数是：CheckIfBecameReady\n在 CheckIfBecameReady 函数中会调用调度函数：SchedulingLoop-\u0026gt;input_stream_handler_-\u0026gt;ScheduleInvocations\ninput_stream_handler_-\u0026gt;ScheduleInvocations 中会调用 schedule_callback_ 回调函数，而这个 schedule_callback_ 回调是 CalculatorNode 给赋值的：\n而 CalculatorNode 的回调是 CalculatorGraph 赋值的，实际是 Scheduler::ScheduleNodeIfNotThrottled\n总结：每次 Node 通过 Output 向下传递数据时，都会到下游的 InputStreamHandler，它会判断 Node 是否 Ready，如果 Ready 则会将 CalculatorNode 放入 ScheduleQueue，同时会从 ScheduleQueue 中根据优先级取出下一个要执行的 CalculatorNode 封装成 Task 提交给 Executor。\nCalculator 可以获得 input stream 的所有数据吗？ # 是不行的，看起来只能访问最旧的消息，那在 graph 的 source node 或者 input 输入时要做流控，不然总是消费最旧的数据：\nAddPacket 的时候有一个 timestamp 是干嘛用的？ # 既像时间戳，又像是 sequence num，在判断 Node 是否 Ready 的时候会通过 timestamp 来判断，下面是 DefaultInputStreamHandler 的判断是否 Ready 的函数：\n看起来要求 timestamp 是严格递增的，如果不递增会在判断 Ready 时不被处理。\nside packet 怎么用？在哪里传入？ # 可以写一个特殊的 Calculator，然后将配置文件的内容转为 side packet，或者直接调用 graph 的接口传入：\nback edge 的作用是什么？ # 见下面的章节：\n2024/06/17 Mediapipe调研\n"},{"id":24,"href":"/posts/1/01/mediapipe%E8%B0%83%E7%A0%94/","title":"Mediapipe调研","section":"Blog","content":" 背景 \u0026amp; 需求 # google 推出的设备端机器学习任务框架：核心模型 + 任务流水线\n需求：\n方便、高效的任务流水线搭建 资源调配与硬件加速，异构并行\u0026amp;同步 跨平台部署：iOS/安卓/Web/嵌入式 Mediapipe 的解决方案 # 任务流水线搭建 # graph、calculator、stream 等概念组成的任务流框架 # calculator：算子，也称为 node\nport：node 的输入输出端口\nstream：node 之间的数据通路\ngraph：任务图\npacket：数据包，timestamp + shared pointer to immutable payload 目前不支持动态调整 graph 结构\ninput/output # input：source nodes 、input streams # source nodes：可以自行产生数据的节点，比如读文件、camera 输入 input streams：由用户将输入给到 graph output：sink nodes、output streams # sink nodes：只有输入没有输出的节点，消耗数据，比如写文件等 output streams：用户从 graph 中拿到输出结果 callback 形式 polling 形式 多源输入数据的同步 # 默认的同步策略：(DefaultInputStreamHandler)\nat least one stream has a packet available at t all other streams either have packets at t, or it is known that they will not have packets at t (i.e. their next timestamp bound is greater than t). 反馈回路 # 条件执行 # side packet # 非数据流数据，比如模型的路径。\nA side-packet connection between nodes carries a single packet with an unspecified timestamp. It can be used to provide some data that will remain constant, whereas a stream represents a flow of data that changes over time. For example, the string defining the file path for an ML model can be fed into a node through a side packet.\nsub graph 实现的 graph 复用 # 大量的 built-in calculator，简化应用开发 # 算法 calculator 数据转换 calculator 数据 I/O calculator 数据处理 calculator 并行处理 calculator 可视化 calculator mediapipe/calculators/ |-- audio |-- core |-- image |-- internal |-- tensor |-- tensorflow |-- tflite |-- util `-- video 运行效率 # 资源调配与硬件加速，异构并行\u0026amp;同步\n调度方案 # 可自定义的执行器 以 calculator 为粒度的调度配置 GPU 加速 # 主要体现在 calculator 层面，部分 calculator 实现了 gpu 版本 提供了一些 gpu 同步原语的封装，以及跨平台的支持（OpenGL、Metal…） 工具支持 # https://viz.mediapipe.dev/\n任务流可视化 # 性能分析工具 # 统计维度 chart view # 过程维度 timeline view # timeline view 有和 dag 的联动\n![](assets/2024-06-17%20Mediapipe调研-20241225191254076-{MD5}.png)![](assets/2024-06-17%20Mediapipe调研-20241225191253871-{MD5}.png) 跨平台部署：iOS/安卓/Web/嵌入式 # 实现 # 主要功能 example # 基本流程（轮询） # graph 启动运行 graph.Initialize(config) 初始化 graph.StartRun({}) 运行 graph.WaitUntilDone() 阻塞等待 graph 中任务全部完成 graph.AddPacketToInputStream() 用户把输入注入 graph 中 OutputStreamPoller.Next(\u0026amp;packet) 用户获取 graph 输出 namespace mediapipe { absl::Status PrintHelloWorld() { // Configures a simple graph, which concatenates 2 PassThroughCalculators. CalculatorGraphConfig config = ParseTextProtoOrDie\u0026lt;CalculatorGraphConfig\u0026gt;(R\u0026#34;pb( input_stream: \u0026#34;in\u0026#34; output_stream: \u0026#34;out\u0026#34; node { calculator: \u0026#34;PassThroughCalculator\u0026#34; input_stream: \u0026#34;in\u0026#34; output_stream: \u0026#34;out1\u0026#34; } node { calculator: \u0026#34;PassThroughCalculator\u0026#34; input_stream: \u0026#34;out1\u0026#34; output_stream: \u0026#34;out\u0026#34; } )pb\u0026#34;); CalculatorGraph graph; graph.Initialize(config); // 必须在graph.StartRun()之前调用，不支持动态添加 OutputStreamPoller poller = std::move(graph.AddOutputStreamPoller(\u0026#34;out\u0026#34;)).value(); graph.StartRun({}); // Give 10 input packets that contains the same string \u0026#34;Hello World!\u0026#34;. // 必须在graph.StartRun()之后调用，否则会被丢弃 for (int i = 0; i \u0026lt; 10; ++i) { graph.AddPacketToInputStream(\u0026#34;in\u0026#34;, MakePacket\u0026lt;std::string\u0026gt;(\u0026#34;Hello World!\u0026#34;).At(Timestamp(i))); } // Close the input stream \u0026#34;in\u0026#34;. // 如果不CloseInputStream，poller.Next 会阻塞等待 graph.CloseInputStream(\u0026#34;in\u0026#34;); mediapipe::Packet packet; // Get the output packets string. while (poller.Next(\u0026amp;packet)) { ABSL_LOG(INFO) \u0026lt;\u0026lt; packet.Get\u0026lt;std::string\u0026gt;(); } return graph.WaitUntilDone(); } } // namespace mediapipe int main(int argc, char** argv) { google::InitGoogleLogging(argv[0]); ABSL_CHECK(mediapipe::PrintHelloWorld().ok()); return 0; } 基本流程（回调） # // 必须在graph.StartRun()之前调用，不支持动态添加 // 添加监听callback，运行在mediapipe executor上下文 graph.ObserveOutputStream(\u0026#34;out\u0026#34;, [](const Packet\u0026amp; packet) { ABSL_LOG(INFO) \u0026lt;\u0026lt; packet.Get\u0026lt;std::string\u0026gt;(); return absl::OkStatus(); }); 自定义 calculator # GetContract() 指定输入输出的数据类型 Open() 初始化逻辑 Process() 数据处理逻辑 Close() 反初始化逻辑 REGISTER_CALCULATOR(xxx) 注册 class MyCalculator : public CalculatorBase { public: static absl::Status GetContract(CalculatorContract* cc) { cc-\u0026gt;Inputs().Index(0).SetAny(); cc-\u0026gt;Outputs().Index(0).SetSameAs(\u0026amp;cc-\u0026gt;Inputs().Index(0)); return absl::OkStatus(); } absl::Status Open(CalculatorContext* cc) final { // Input: arbitrary Packets. // Output: copy of the input. cc-\u0026gt;Outputs().Index(0).SetHeader(cc-\u0026gt;Inputs().Index(0).Header()); ABSL_LOG(INFO) \u0026lt;\u0026lt; \u0026#34;Open will only be called once\u0026#34;; return absl::OkStatus(); } absl::Status Process(CalculatorContext* cc) final { auto count = cc-\u0026gt;GetCounter(\u0026#34;MyCalculator\u0026#34;)-\u0026gt;Get(); auto input_packet_content = cc-\u0026gt;Inputs().Index(0).Value().Get\u0026lt;std::string\u0026gt;(); cc-\u0026gt;Outputs().Index(0).AddPacket( MakePacket\u0026lt;std::string\u0026gt;(input_packet_content + \u0026#34;-\u0026#34; + std::to_string(count)) .At(Timestamp(count))); cc-\u0026gt;GetCounter(\u0026#34;MyCalculator\u0026#34;)-\u0026gt;Increment(); return absl::OkStatus(); } absl::Status Close(CalculatorContext* cc) final { ABSL_LOG(INFO) \u0026lt;\u0026lt; \u0026#34;Close will only be called once\u0026#34;; return absl::OkStatus(); } }; REGISTER_CALCULATOR(MyCalculator); steam 标识 # 在 calculator 中，通过 index number 或 tag name 来指定具体的输入输出 stream，两者也可以混用\nCalculatorGraphConfig config = ParseTextProtoOrDie\u0026lt;CalculatorGraphConfig\u0026gt;(R\u0026#34;pb( input_stream: \u0026#34;camera\u0026#34; input_stream: \u0026#34;left\u0026#34; input_stream: \u0026#34;right\u0026#34; output_stream: \u0026#34;out_0\u0026#34; output_stream: \u0026#34;out_1\u0026#34; node { calculator: \u0026#34;MyCalculator\u0026#34; input_stream: \u0026#34;IMAGE:camera\u0026#34; input_stream: \u0026#34;VIDEO:0:left\u0026#34; input_stream: \u0026#34;VIDEO:1:right\u0026#34; output_stream: \u0026#39;out_0\u0026#39; output_stream: \u0026#39;out_1\u0026#39; } )pb\u0026#34;); static absl::Status GetContract(CalculatorContract* cc) { cc-\u0026gt;Inputs().Tag(\u0026#34;IMAGE\u0026#34;).SetAny(); cc-\u0026gt;Inputs().Get(\u0026#34;VIDEO\u0026#34;, 0).Set\u0026lt;std::string\u0026gt;(); cc-\u0026gt;Inputs().Get(\u0026#34;VIDEO\u0026#34;, 1).Set\u0026lt;int\u0026gt;(); cc-\u0026gt;Outputs().Index(0).Set\u0026lt;int\u0026gt;(); cc-\u0026gt;Outputs().Index(1).Set\u0026lt;float\u0026gt;(); return absl::OkStatus(); } 源节点 # 没有 input_stream 的 node 将始终处于 ready 状态，直到没有更多数据可输出时会被框架关闭\nclass SourceCalculator : public CalculatorBase { public: static absl::Status GetContract(CalculatorContract* cc) { cc-\u0026gt;Outputs().Index(0).Set\u0026lt;int\u0026gt;(); return absl::OkStatus(); } absl::Status Open(CalculatorContext* cc) final { return absl::OkStatus(); } absl::Status Process(CalculatorContext* cc) final { if (index_++ \u0026gt; 100) { return tool::StatusStop(); } cc-\u0026gt;Outputs().Index(0).AddPacket( MakePacket\u0026lt;int\u0026gt;(index_).At(Timestamp(index_))); return absl::OkStatus(); } absl::Status Close(CalculatorContext* cc) final { return absl::OkStatus(); } private: int index_{0}; }; REGISTER_CALCULATOR(SourceCalculator); 数据同步（input_stream_handler） # calculator 有多个输入源时，通过 input_stream_handler 指定 node 何时可被调度，主要需要写两个接口：\nGetNodeReadiness scheduler 通过该接口获取同步是否完成\n// Indicates the operation the node is ready for. enum class NodeReadiness { // The node is not ready. kNotReady, // The node is ready and we should run Process(). kReadyForProcess, // The node is ready and we should run Close(). kReadyForClose, }; 调用时机：\n如果之前 not ready，任一 stream 从空到非空时会再检查一次 如果 ready，运行完任务会再检查一次 FillInputSet(Timestamp, InputStreamShardSet*) 同步完成时，调度器调用该接口，填充消息 back edge # 默认的 graph 是 DAG，但也允许有环，需要显示标注为“back_edge”；\ngraph 初始化时会检查去掉 back_edge 后的图是 DAG\n一个常见用法是作为流控，主动丢弃一些旧数据来实现实时处理的效果。\n因为 stream 是队列满后阻塞写，默认 queue size 为 100；queue 满了会阻塞写入 api 可以在配置中指定 max_queue_size（整个 graph 的配置） node 层可指定 buffer_size_hint 来覆盖，会取两者最大值 class FlowLimiterCalculator : public CalculatorBase { public: static absl::Status GetContract(CalculatorContract* cc) { // ... cc-\u0026gt;SetInputStreamHandler(\u0026#34;ImmediateInputStreamHandler\u0026#34;); // ... } // ... sub graph # 可以通过 REGISTER_MEDIAPIPE_GRAPH，将一个 graph 注册为 sub-graph，在其他 graph 中作为一个 node 实现复用\nclass DemoSubgraph : public Subgraph { public: absl::StatusOr\u0026lt;CalculatorGraphConfig\u0026gt; GetConfig( const SubgraphOptions\u0026amp; options) override { CalculatorGraphConfig config = mediapipe::ParseTextProtoOrDie\u0026lt;CalculatorGraphConfig\u0026gt;(R\u0026#34;pb( input_stream: \u0026#39;INPUT:in\u0026#39; output_stream: \u0026#39;OUTPUT:out\u0026#39; node { calculator: \u0026#39;PassThroughCalculator\u0026#39; input_stream: \u0026#39;in\u0026#39; output_stream: \u0026#39;out\u0026#39; } )pb\u0026#34;); return config; } }; REGISTER_MEDIAPIPE_GRAPH(DemoSubgraph); CalculatorGraphConfig config = ParseTextProtoOrDie\u0026lt;CalculatorGraphConfig\u0026gt;(R\u0026#34;pb( input_stream: \u0026#34;input\u0026#34; output_stream: \u0026#34;out\u0026#34; node { calculator: \u0026#34;DemoSubgraph\u0026#34; input_stream: \u0026#34;INPUT:input\u0026#34; output_stream: \u0026#34;OUTPUT:temp\u0026#34; } node { calculator: \u0026#34;PassThroughCalculator\u0026#34; input_stream: \u0026#34;temp\u0026#34; output_stream: \u0026#34;out\u0026#34; } )pb\u0026#34;); user executor # 基本结构 # scheduler + executor Graph 有至少一个 SchedulerQueue 每个 SchedulerQueue 对应一个 Executor scheduler 负责决定执行哪个任务 executor 负责执行 默认所有 calculator 共用一个 thread pool 用户可自定义扩展 executor；可以为每个 calculator 指定不同的 executor 自定义 executor # CalculatorGraphConfig config = ParseTextProtoOrDie\u0026lt;CalculatorGraphConfig\u0026gt;(R\u0026#34;pb( input_stream: \u0026#34;input\u0026#34; output_stream: \u0026#34;out\u0026#34; executor { name: \u0026#39;my_executor\u0026#39; type: \u0026#39;MyExecutor\u0026#39; } node { calculator: \u0026#34;PassThroughCalculator\u0026#34; input_stream: \u0026#34;input\u0026#34; output_stream: \u0026#34;temp\u0026#34; executor: \u0026#34;my_executor\u0026#34; } node { calculator: \u0026#34;PassThroughCalculator\u0026#34; input_stream: \u0026#34;temp\u0026#34; output_stream: \u0026#34;out\u0026#34; executor: \u0026#34;my_executor\u0026#34; } )pb\u0026#34;); 主要需要实现 AddTask 和 Schedule 两个接口\nvirtual void AddTask(TaskQueue* task_queue) 一个可执行的 calculator + 一组输入数据作为一个任务，包装在 TaskQueue 中 Scheduler 把 ready 的任务给到 Executor，由 Executor 决定如何执行 task_queue-\u0026gt;RunNextTask() void Schedule(std::function\u0026lt;void()\u0026gt; task) 具体执行任务的逻辑\n感觉主要是为了方便，默认 AddTask 会调用 Schedule 来执行 task_queue-\u0026gt;RunNextTask()，所以用户只需要 override Schedule 就行 比如默认 ThreadPoolExecutor 的实现：\nvoid ThreadPoolExecutor::Schedule(std::function\u0026lt;void()\u0026gt; task) { thread_pool_.Schedule(std::move(task)); } 调度策略 # scheduler 是静态固定优先级，根据拓扑排序算出来，越靠近输出优先级越高\nWhen a node becomes ready, a task is added to the corresponding scheduler queue, which is a priority queue. The priority function is currently fixed, and takes into account static properties of the nodes and their topological sorting within the graph. For example, nodes closer to the output side of the graph have higher priority, while source nodes have the lowest priority.\n初始化阶段，拓扑排序，给每个 node 分配 id\nabsl::Status ValidatedGraphConfig::TopologicalSortNodes() 实际运行时，调度队列是一个根据 id 的优先级队列，决定下一个运行的 ready node\nmediapipe/framework/scheduler_queue.cc // Returning true means \u0026#34;this runs after that\u0026#34;. bool SchedulerQueue::Item::operator\u0026lt;(const SchedulerQueue::Item\u0026amp; that) const { if (is_open_node_ || that.is_open_node_) { // OpenNode() runs before ProcessNode(). if (!that.is_open_node_) return false; // ProcessNode() runs after OpenNode(). if (!is_open_node_) return true; // If both are OpenNode(), higher ids run after lower ids. return id_ \u0026gt; that.id_; } if (is_source_) { // Sources run after non-sources. if (!that.is_source_) return true; // Higher layer sources run after lower layer sources. if (layer_ != that.layer_) return layer_ \u0026gt; that.layer_; // Higher SourceProcessOrder values run after lower values. if (source_process_order_ != that.source_process_order_) { return source_process_order_ \u0026gt; that.source_process_order_; } // For sources, higher ids run after lower ids. return id_ \u0026gt; that.id_; } else { // Non-sources run before sources. if (that.is_source_) return false; // For non-sources, higher ids run before lower ids. return id_ \u0026lt; that.id_; } } 其他 # Calculator 中如果有阻塞逻辑会卡住当前线程，这点感觉不如 CyberRT 的协程方案 TODO：其他功能 demo # side packet status_handler packet generator time bound api2 代码结构 # 类之间关系 基本流程 传递的数据结构：Packet 动态分配，具体 payload 共享，时间戳可以不同 graph.AddPacketToInputStream( \u0026#34;in\u0026#34;, MakePacket\u0026lt;std::string\u0026gt;(\u0026#34;Hello World!\u0026#34;).At(Timestamp(i)) ); 目录结构 Reference # 相关链接 # repo：https://github.com/google-ai-edge/mediapipe\n文档：https://ai.google.dev/edge/mediapipe/framework\n论文：https://arxiv.org/pdf/1906.08172\n团队成员分享：https://mp.weixin.qq.com/s/pIyLdRpL_mzK5XCH2DEkdQ\n"},{"id":25,"href":"/posts/1/01/spark-mongodb/","title":"spark \u0026 mongodb","section":"Blog","content":" spark # https://spark.apache.org/docs/latest/api/python/index.html#index-page-spark-sql-and-dataframes\nSpark SQL \u0026amp; DataFrames spark.createDataFrame df.show() df.columns df.printSchema() Pandas API on Spark Structured Streaming Machine Learning mongodb # 安装 # https://www.mongodb.com/zh-cn/docs/v6.0/tutorial/install-mongodb-on-os-x/\n启停服务 # brew services stop mongodb-community@7.0 配置文件 # https://www.mongodb.com/zh-cn/docs/v6.0/reference/configuration-options/\ndebug # 要验证 MongoDB 是否正在运行，请执行以下操作之一：\n如果将 MongoDB 作为 macOS 服务启动： brew services list 应该会看到服务 mongodb-community 列为 started。\n如果将 MongoDB 作为后台进程手动启动： ps aux | grep -v grep | grep mongod 应该在输出中看到 mongod 进程。\n还可以查看日志文件，看到 mongod 进程的当前状态：/usr/local/var/log/mongodb/mongo.log。\n"},{"id":26,"href":"/posts/1/01/%E4%BD%BF%E7%94%A8bazel%E7%BC%96%E8%AF%91rust%E9%A1%B9%E7%9B%AE/","title":"使用bazel编译rust项目","section":"Blog","content":" 编译适配 # 主要参考：https://www.tweag.io/blog/2023-07-27-building-rust-workspace-with-bazel/\n1）加入rules_rust # 在WORKSPACE中加入：\nhttp_archive( name = \u0026#34;rules_rust\u0026#34;, sha256 = \u0026#34;36ab8f9facae745c9c9c1b33d225623d976e78f2cc3f729b7973d8c20934ab95\u0026#34;, urls = [\u0026#34;https://github.com/bazelbuild/rules_rust/releases/download/0.31.0/rules_rust-v0.31.0.tar.gz\u0026#34; ], ) load(\u0026#34;@rules_rust//rust:repositories.bzl\u0026#34;, \u0026#34;rules_rust_dependencies\u0026#34;, \u0026#34;rust_register_toolchains\u0026#34;) rules_rust_dependencies() rust_register_toolchains() # 声明使用的rust版本，最新的是2024，我选了一个次新的 rust_register_toolchains( edition = \u0026#34;2021\u0026#34;, ) 2）设置外部依赖 # 添加外部依赖，在WORKSPACE中添加：\nload(\u0026#34;@rules_rust//crate_universe:repositories.bzl\u0026#34;, \u0026#34;crate_universe_dependencies\u0026#34;) crate_universe_dependencies() load(\u0026#34;@rules_rust//crate_universe:defs.bzl\u0026#34;, \u0026#34;crates_repository\u0026#34;) crates_repository( name = \u0026#34;crate_index\u0026#34;, cargo_lockfile = \u0026#34;//xxx_tool:Cargo.lock\u0026#34;, lockfile = \u0026#34;//:cargo-bazel-lock.json\u0026#34;, manifests = [ \u0026#34;//xxx_tool:Cargo.toml\u0026#34;, \u0026#34;//xxx_tool/common:Cargo.toml\u0026#34;, \u0026#34;//xxx_tool/xxx_monitor:Cargo.toml\u0026#34;, ], generate_build_scripts = True, ) load(\u0026#34;@crate_index//:defs.bzl\u0026#34;, \u0026#34;crate_repositories\u0026#34;) crate_repositories() 必须先执行一下：\ntouch cargo-bazel-lock.json CARGO_BAZEL_REPIN=1 bazel sync --only=crate_index 执行上述命令会读取Cargo.toml和Cargo.lock，并将依赖信息写到cargo-bazel-lock.json中，通过bazel命令可以查询具体包含了哪些依赖：\nbazel query @crate_index//... 3）添加target规则 # package(default_visibility = [\u0026#34;//visibility:public\u0026#34;]) load(\u0026#34;@rules_rust//rust:defs.bzl\u0026#34;, \u0026#34;rust_library\u0026#34;) rust_library( name = \u0026#34;common\u0026#34;, srcs = glob([ \u0026#34;src/**/*.rs\u0026#34;, ]), edition = \u0026#34;2021\u0026#34;, deps = [ \u0026#34;@crate_index//:chrono\u0026#34;, \u0026#34;@crate_index//:lazy_static\u0026#34;, \u0026#34;@crate_index//:log\u0026#34;, \u0026#34;@crate_index//:log4rs\u0026#34;, \u0026#34;@crate_index//:nix\u0026#34;, \u0026#34;@crate_index//:serde\u0026#34;, \u0026#34;@crate_index//:tokio\u0026#34;, \u0026#34;@crate_index//:uname\u0026#34;, ], proc_macro_deps = [ \u0026#34;@crate_index//:serde_derive\u0026#34;, ], ) Rust call c++编译问题 # rust调用c++代码，一般几种方式：cxx、autocxx、bindgen 此前用的autocxx，相对来说是最方便使用的，不需要自己手动写大量的胶水层代码 autocxx本身目前没有现成的bazel方案，但一些开源相关工作可以参考： autocxx仓库的bazel PR：https://github.com/google/autocxx/pull/1255 有一个开源库，自己做了autocxx的bazel集成：https://github.com/frc971/971-Robot-Code/blob/main/tools/build_rules/autocxx.bzl autocxx的原理介绍： https://google.github.io/autocxx/building.html 重点是通过autocxx-gen工具，生成对应的cpp/rs胶水层代码并编译。 之前的build.rs脚本中autocxx提供的函数其实就是封装了这一过程。 生成过程 # 先把依赖的几个proto编译一下，把头文件生成出来。 然后执行autocxx-gen autocxx-gen ./xxx.rs \\ --outdir ./test-output/ \\ --gen-cpp \\ --gen-rs-include \\ --inc ./ \\ --inc ./bazel-bin \\ 参数解释： cpp_interface.rs：调用了c++的rust代码 \u0026ndash;outdir：输出文件夹 \u0026ndash;gen-cpp：指定生成c++胶水层代码 \u0026ndash;gen-rs-include：指定生成rust胶水层代码 \u0026ndash;inc：按需指定依赖的各个头文件路径 "},{"id":27,"href":"/posts/1/01/%E6%B8%85%E7%90%86dns/","title":"清理DNS","section":"Blog","content":"sudo killall -HUP mDNSResponder\n"},{"id":28,"href":"/posts/1/01/%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/","title":"环境配置","section":"Blog","content":"{% raw %}\nmac环境 # 整理launcher # defaults write com.apple.dock ResetLaunchPad -bool true \u0026amp;\u0026amp; killall Dock iterm2快捷键 # 【command + 数字 command + 左右方向键】切换标签 【command + f】查找 【command + d】垂直分屏 【command + shift + d】水平分屏 【command + option + 方向键 command + [或 command +] 】切换屏幕 【command + ;】查看历史命令 【command + shift + h】查看剪贴板历史 【ctrl + u】清除当前行 【ctrl + l】清屏\n【ctrl + f/b】 前进后退 【ctrl + p】 上一条命令\nhttps://www.jianshu.com/p/a78845c3f476\n快捷键cmd+shift+enter，能够将某一个全屏化当前分屏，满足全屏编辑的需求 搜索及文本复制\n使用“cmd+f”可以调出搜索框进行文本搜索，然后有个很奇妙的快捷键“tab”键，使用它后会自动高亮当前文本后面的内容。最后按enter键将高亮文本复制到剪切板上\npython # pyenv # mkdir ~/.venv python3 -m venv ~/.venv #\tCreates the following in ~/.venv #\tbin/ #\tinclude/ #\tlib/ #\tpyvenv.cfg #\tdoes not create pip-selfcheck.json # to activate the venv source ~/.venv/bin/activate # now you can.. python3 -m pip install \u0026lt;module name\u0026gt; # and it will install the module in the virtual env # to deactivate the venv deactivate # or exit the shell # you should see the folder name for the venv below your prompt when active, like so pstivers3@mbp ~/repos/learn/pythonlearn $ (.venv) # Note, you can chose any folder location and name that you want for the venv. ~/.venv is typical. # Your project code can be in any directory. Vscode # settings.json # vim # \u0026#34;vim.handleKeys\u0026#34;: { \u0026#34;\u0026lt;C-f\u0026gt;\u0026#34;: false, }, scrollBeyondLastLine # false\ngo forward / go back # keyboard bindings设置\n插件 # Dracula Official GitLens Vim C/C++ 通过vscode使用docker # 参考：https://zhuanlan.zhihu.com/p/654973364\nhttps://code.visualstudio.com/docs/devcontainers/containers\n创建 .devcontainer文件夹\n{ \u0026#34;name\u0026#34;: \u0026#34;c/c++\u0026#34;, \u0026#34;build\u0026#34;: { \u0026#34;dockerfile\u0026#34;: \u0026#34;Dockerfile\u0026#34; }, // Features to add to the dev container. More info: https://containers.dev/features. // \u0026#34;features\u0026#34;: {}, // Use \u0026#39;forwardPorts\u0026#39; to make a list of ports inside the container available locally. // \u0026#34;forwardPorts\u0026#34;: [], // Use \u0026#39;postCreateCommand\u0026#39; to run commands after the container is created. // \u0026#34;postCreateCommand\u0026#34;: \u0026#34;gcc -v\u0026#34;, // Configure tool-specific properties. \u0026#34;customizations\u0026#34;: { \u0026#34;vscode\u0026#34;: { // Add the IDs of extensions you want installed when the container is created. \u0026#34;extensions\u0026#34;: [ \u0026#34;ms-vscode.cpptools\u0026#34;, \u0026#34;ms-vscode.cmake-tools\u0026#34;, \u0026#34;ms-python.vscode-pylance\u0026#34; ] } }, // Uncomment to connect as root instead. More info: https://aka.ms/dev-containers-non-root. \u0026#34;remoteUser\u0026#34;: \u0026#34;vscode\u0026#34; } FROM devuan/devuan ARG USERNAME=vscode ARG USER_UID=1000 ARG USER_GID=$USER_UID # Create the user RUN groupadd --gid $USER_GID $USERNAME \\ \u0026amp;\u0026amp; useradd --uid $USER_UID --gid $USER_GID -m $USERNAME \\ # # [Optional] Add sudo support. Omit if you don\u0026#39;t need to install software after connecting. \u0026amp;\u0026amp; apt-get update \\ \u0026amp;\u0026amp; apt-get install -y sudo \\ \u0026amp;\u0026amp; echo $USERNAME ALL=\\(root\\) NOPASSWD:ALL \u0026gt; /etc/sudoers.d/$USERNAME \\ \u0026amp;\u0026amp; chmod 0440 /etc/sudoers.d/$USERNAME # [Optional] Set the default user. Omit if you want to keep the default as root. # USER $USERNAME RUN apt-get update \u0026amp;\u0026amp; export DEBIAN_FRONTEND=noninteractive \\ \u0026amp;\u0026amp; apt-get -y install --no-install-recommends git cmake gdb build-essential clang \\ clang-tidy clang-format pkg-config glibc-doc tcpdump tshark zsh tmux libreadline-dev Ubuntu # bashrc # alias cd=\u0026#39;new() { cd $1; ls ; }; new\u0026#39; alias gg=\u0026#39;new() { grep $1 ./ -r; }; new\u0026#39; #for git alias gst=\u0026#39;git status\u0026#39; alias gd=\u0026#39;git diff\u0026#39; alias gdc=\u0026#39;git diff --cached\u0026#39; alias gck=\u0026#39;git checkout\u0026#39; alias gb=\u0026#39;git branch\u0026#39; alias gpr=\u0026#39;git pull --rebase\u0026#39; alias glog=\u0026#39;git log --graph --pretty=format:\u0026#34;%Cred%h%Creset - %Cgreen(%cD) %C(bold blue)\u0026lt;%an\u0026gt;%Creset %C(yellow)%d%Creset %n%s %n\u0026#34; --abbrev-commit --branches --decorate\u0026#39; PS1 # tput # https://linuxcommand.org/lc3_adv_tput.php\n颜色 # txtblk=\u0026#39;\\e[0;30m\u0026#39; # Black - Regular txtred=\u0026#39;\\e[0;31m\u0026#39; # Red txtgrn=\u0026#39;\\e[0;32m\u0026#39; # Green txtylw=\u0026#39;\\e[0;33m\u0026#39; # Yellow txtblu=\u0026#39;\\e[0;34m\u0026#39; # Blue txtpur=\u0026#39;\\e[0;35m\u0026#39; # Purple txtcyn=\u0026#39;\\e[0;36m\u0026#39; # Cyan txtwht=\u0026#39;\\e[0;37m\u0026#39; # White bldblk=\u0026#39;\\e[1;30m\u0026#39; # Black - Bold bldred=\u0026#39;\\e[1;31m\u0026#39; # Red bldgrn=\u0026#39;\\e[1;32m\u0026#39; # Green bldylw=\u0026#39;\\e[1;33m\u0026#39; # Yellow bldblu=\u0026#39;\\e[1;34m\u0026#39; # Blue bldpur=\u0026#39;\\e[1;35m\u0026#39; # Purple bldcyn=\u0026#39;\\e[1;36m\u0026#39; # Cyan bldwht=\u0026#39;\\e[1;37m\u0026#39; # White unkblk=\u0026#39;\\e[4;30m\u0026#39; # Black - Underline undred=\u0026#39;\\e[4;31m\u0026#39; # Red undgrn=\u0026#39;\\e[4;32m\u0026#39; # Green undylw=\u0026#39;\\e[4;33m\u0026#39; # Yellow undblu=\u0026#39;\\e[4;34m\u0026#39; # Blue undpur=\u0026#39;\\e[4;35m\u0026#39; # Purple undcyn=\u0026#39;\\e[4;36m\u0026#39; # Cyan undwht=\u0026#39;\\e[4;37m\u0026#39; # White bakblk=\u0026#39;\\e[40m\u0026#39; # Black - Background bakred=\u0026#39;\\e[41m\u0026#39; # Red bakgrn=\u0026#39;\\e[42m\u0026#39; # Green bakylw=\u0026#39;\\e[43m\u0026#39; # Yellow bakblu=\u0026#39;\\e[44m\u0026#39; # Blue bakpur=\u0026#39;\\e[45m\u0026#39; # Purple bakcyn=\u0026#39;\\e[46m\u0026#39; # Cyan bakwht=\u0026#39;\\e[47m\u0026#39; # White txtrst=\u0026#39;\\e[0m\u0026#39; # Text Reset https://askubuntu.com/questions/558280/changing-colour-of-text-and-background-of-terminal\nbashrc color解释 # Information as found on this page, excluding preview column: Sequences are composed of the Escape character (often represented by ”^[” or ””) followed by some other characters: ”^[FCm” (where FC is one of the numbers in the bulleted list below). In bash, the Esc code can be either of the following:\n\\e \\033 (octal) \\x1B (hexadecimal) Note 1: The \u0026ldquo;\\e[0m\u0026rdquo; sequence removes all attributes (formatting and colors). It can be a good idea to add it at the end of each colored text. Note 2: Foreground and background colours may vary, depending on the terminal\u0026rsquo;s configuration and not all colours are supported. Set/Reset # 0: Reset/remove all modifier, foreground and background attributes: echo -e \u0026ldquo;\\e[0mNormal Text\u0026rdquo; 1: Bold/Bright: echo -e \u0026ldquo;Normal \\e[1mBold\u0026rdquo; 2: Dim: echo -e \u0026ldquo;Normal \\e[2mDim\u0026rdquo; 4: Underlined: echo -e \u0026ldquo;Normal \\e[4mUnderlined\u0026rdquo; 5: Blink (doesn\u0026rsquo;t work in most terminals except XTerm): echo -e \u0026ldquo;Normal \\e[5mBlink\u0026rdquo; 7: Reverse/Invert: echo -e \u0026ldquo;Normal \\e[7minverted\u0026rdquo; 8: Hidden (useful for sensitive info): echo -e \u0026ldquo;Normal \\e[8mHidden Input\u0026rdquo; 21: Reset/Remove bold/bright: echo -e \u0026ldquo;Normal \\e[1mBold \\e[21mNormal\u0026rdquo; 22: Reset/Remove dim: echo -e \u0026ldquo;Normal \\e[2mDim \\e[22mNormal\u0026rdquo; 24: Reset/Remove underline: echo -e \u0026ldquo;Normal \\e[4mUnderlined \\e[24mNormal\u0026rdquo; 25: Reset/Remove blink: echo -e \u0026ldquo;Normal \\e[5mBlink \\e[25mNormal\u0026rdquo; 27: Reset/Remove reverse/invert: echo -e \u0026ldquo;Normal \\e[7minverted \\e[27mNormal\u0026rdquo; 28: Reset/Remove hidden: echo -e \u0026ldquo;Normal \\e[8mHidden \\e[28mNormal\u0026rdquo; Foreground # 39: Default (usually green, white or light gray): echo -e \u0026ldquo;Default \\e[39mDefault\u0026rdquo; 30: Black: echo -e \u0026ldquo;Default \\e[30mBlack\u0026rdquo; (best combined with a background colour: echo -e \u0026ldquo;Default \\e[30;107mBlack on white\u0026rdquo;) 31: Red (don\u0026rsquo;t use with green background) 32: Green 33: Yellow 34: Blue 35: Magenta/Purple 36: Cyan 37: Light Gray 90: Dark Gray 91: Light Red 92: Light Green 93: Light Yellow 94: Light Blue 95: Light Magenta/Pink 96: Light Cyan 97: White Background # 49: Default background color (usually black or blue) 40: Black 41: Red 42: Green 43: Yellow 44: Blue 45: Magenta/Purple 46: Cyan 47: Light Gray (don\u0026rsquo;t use with white foreground) 100: Dark Gray (don\u0026rsquo;t use with black foreground) 101: Light Red 102: Light Green (don\u0026rsquo;t use with white foreground) 103: Light Yellow (don\u0026rsquo;t use with white foreground) 104: Light Blue (don\u0026rsquo;t use with light yellow foreground) 105: Light Magenta/Pink (don\u0026rsquo;t use with light foreground) 106: Light Cyan (don\u0026rsquo;t use with white foreground) 107: White (don\u0026rsquo;t use with light foreground) To set both the foreground and background colours at once, use ther form echo -e \u0026ldquo;\\e[S;FG;BGm\u0026rdquo;. For example: echo -e \u0026ldquo;\\e[1;97;41m\u0026rdquo; (bold white foreground on red background) For 256 colour options, see the source page.\n这篇文章也不错：https://www.baeldung.com/linux/customize-bash-prompt\nEscape Characters # There’s a list of predefined escape characters with special decoding. These characters are preceded by the backslash character. Some examples are:\n\\d: The current date \\t: The current time \\h: The hostname of our Linux machine \\u: The username of the logged-in user \\w: The user’s working directory [: Beginning of a sequence of non-printable characters that somehow control the behavior of the terminal ]: End of non-printable control characters sequence Colors # A color character sequence\nstarts with：\n[\\033[ [e[ and ends with：\n] In addition, it should contain a code to a corresponding color.\nColor codes comprise two parts, separated by a semicolon, and are followed by the letter m.\nThe first part：\n0 for the dark version 1 for the light version The second part defines the color.\nMoreover, all codes that set the font color start with digit 3. Color codes that start with digit 4 define the background color. add the 4m code to underline the promp $ PS1=\u0026#34;\\[\\033[1;33;42;4m\\]\\d:\\t$ \\[\\033[0m\\]\u0026#34; PS1 # $ export PS1=\u0026#39;\\e[1m\\]\\e[3;32m\\]\\u\\e[0;34m\\]@\\e[1;32m\\]\\H \\e[1;34m\\]\\t \\e[1m\\]\\e[3;30m\\]\\w \\e[0m\\]\\n\\$ \u0026#39; \\e[1;32m\\][ 加粗绿色显示[ \\e[1m\\]\\e[3;35m\\]\\u 加粗斜体紫红色显示用户名 \\e[0;34m\\]@ 默认样式蓝色显示@ \\e[1;33m\\]\\H 加粗黄色显示主机名 \\e[1;32m\\]][ 加粗绿色显示][ \\e[1;34m\\]\\t 加粗蓝色显示时间 \\e[1;32m\\]] 加粗绿色显示]和空格 \\e[1m\\]\\e[3;30m\\]\\w 加粗斜体黑色显示工作路径 \\e[0m\\]\\n\\$ 清除所有格式，换行显示提示符，注意提示符后有空格 ———————————————— 原文链接：https://blog.csdn.net/u014001096/article/details/125689548 #################################################################### export PS1=\u0026#39;\\[\\033[01;32m\\]\\u\\[\\033[00m\\]\\[\\033[01;30m\\]@\\t\\[\\033[00m\\]:\\[\\033[01;34m\\]\\w\\[\\033[00m\\]\\$ \u0026#39; \\[\\033[01;32m\\]\\u\\[\\033[00m\\] \\[\\033[01;30m\\]@\\t\\[\\033[00m\\] : \\[\\033[01;34m\\]\\w\\[\\033[00m\\] \\$ #################################################################### \\e[0;32m - sets colour (in this case, to green) \\e[m - sets colour back to the default #################################################################### parse_git_bg() { if [[ $(git status -s 2\u0026gt; /dev/null) ]]; then echo -e \u0026#34;\\033[1;31m\u0026#34; else echo -e \u0026#34;\\033[1;32m\u0026#34; fi } export GIT_PS1_SHOWDIRTYSTATE=1 export PS1=\u0026#39;\\[$(parse_git_bg)\\]$(__git_ps1 \u0026#34;(%s) \u0026#34;)\\[\\e[1;32m\\]\\u\\[\\e[0;39m\\]@\\[\\e[1;36m\\]\\D{%F %T}\\[\\e[0;39m\\]:\\[\\e[1;33m\\]\\w\\[\\e[0;39m\\]\\[\\033[0m\\]\\$ \u0026#39; 日期 时间：\\D{%F %T} #################################################################### # for PS1 source ~/.git-completion.bash source ~/.git-prompt.sh export GIT_PS1_SHOWDIRTYSTATE=true # staged \u0026#39;+\u0026#39;, unstaged \u0026#39;*\u0026#39; export GIT_PS1_SHOWUNTRACKEDFILES=true # \u0026#39;%\u0026#39; untracked files export GIT_PS1_SHOWUPSTREAM=\u0026#34;auto\u0026#34; # \u0026#39;\u0026lt;\u0026#39; behind, \u0026#39;\u0026gt;\u0026#39; ahead, \u0026#39;\u0026lt;\u0026gt;\u0026#39; diverged, \u0026#39;=\u0026#39; no difference export GIT_PS1_SHOWSTASHSTATE=true # \u0026#39;$\u0026#39; something is stashed export GIT_PS1_DESCRIBE_STYLE=branch export GIT_PS1_SHOWCOLORHINTS=1 bldblk=\u0026#34;\\[\\e[1;30m\\]\u0026#34; # Black - Bold bldred=\u0026#34;\\[\\e[1;31m\\]\u0026#34; # Red bldgrn=\u0026#34;\\[\\e[1;32m\\]\u0026#34; # Green bldylw=\u0026#34;\\[\\e[1;33m\\]\u0026#34; # Yellow bldblu=\u0026#34;\\[\\e[1;34m\\]\u0026#34; # Blue bldpur=\u0026#34;\\[\\e[1;35m\\]\u0026#34; # Purple bldcyn=\u0026#34;\\[\\e[1;36m\\]\u0026#34; # Cyan bldwht=\u0026#34;\\[\\e[1;37m\\]\u0026#34; # White bakblk=\u0026#34;\\[\\e[40m\\]\u0026#34; # Black - Background bakred=\u0026#34;\\[\\e[41m\\]\u0026#34; # Red bakgrn=\u0026#34;\\[\\e[42m\\]\u0026#34; # Green bakylw=\u0026#34;\\[\\e[43m\\]\u0026#34; # Yellow bakblu=\u0026#34;\\[\\e[44m\\]\u0026#34; # Blue bakpur=\u0026#34;\\[\\e[45m\\]\u0026#34; # Purple bakcyn=\u0026#34;\\[\\e[46m\\]\u0026#34; # Cyan bakwht=\u0026#34;\\[\\e[47m\\]\u0026#34; # White txtrst=\u0026#34;\\[\\e[0m\\]\u0026#34; # Text Reset PS1=\u0026#34;${bakcyn}DOCKER${txtrst} \u0026#34; # PS1+=\u0026#34;\\$(__git_ps1\u0026#34;(%s) \u0026#34;)${COLOR_RESET}\u0026#34; PS1+=\u0026#39;$(__git_ps1 \u0026#34;(%s) \u0026#34;)${COLOR_RESET}\u0026#39; PS1+=\u0026#34;${bakwht}${bldwht}\\u${txtrst}\u0026#34; PS1+=\u0026#34;${bldblu}@\u0026#34; PS1+=\u0026#34;${bldpur}\\D{%F %T}\u0026#34; PS1+=\u0026#34;${bldwht}:${bldcyn}\\w${txtrst}\\$ \u0026#34; #### FINAL PS1=\u0026#34;$(tput bold)$(tput rev)$(tput setaf 4)\\u$(tput setaf 9)@$(tput setaf 5)\\D{%F %T}$(tput setaf 9):$(tput setaf 6)\\w$(tput sgr0)\\n\\$ \u0026#34; __git_ps1 # https://anotheruiguy.gitbooks.io/gitforeveryone/content/auto/README.html\ncurl https://raw.githubusercontent.com/git/git/master/contrib/completion/git-completion.bash \u0026gt; ~/.git-completion.bash curl -o ~/.git-prompt.sh https://raw.githubusercontent.com/git/git/master/contrib/completion/git-prompt.sh source ~/.git-completion.bash GIT_PS1_SHOWDIRTYSTATE=true GIT_PS1_SHOWSTASHSTATE=true GIT_PS1_SHOWUPSTREAM=\u0026#34;auto\u0026#34; source ~/.git-prompt.sh 时区 # export TZ=Asia/Shanghai gitconfig # git config --global core.editor vim [user] email = ljq0831@qq.com name = Jiaqi Li [core] editor = vim vimrc # \u0026#34; Highlight cursor line underneath the cursor horizontally. set cursorline \u0026#34; Set shift width to 4 spaces. set shiftwidth=4 \u0026#34; Set tab width to 4 columns. set tabstop=4 \u0026#34; Use space characters instead of tabs. set expandtab \u0026#34; Show partial command you type in the last line of the screen. set showcmd \u0026#34; Show the mode you are on the last line. set showmode \u0026#34; Show matching words during a search. set showmatch \u0026#34; Use highlighting when doing a search. set hlsearch set nu Terminator # https://github.com/gnome-terminator/terminator/blob/master/INSTALL.md\nsudo add-apt-repository ppa:mattrose/terminator sudo apt-get update sudo apt install terminator docker # 参考：\nhttps://solider245.github.io/VuePress-blog/%E6%96%87%E7%AB%A0%E8%BD%AC%E8%BD%BD/docker/mac%20%E4%B8%8B%E4%BD%BF%E7%94%A8%20Docker%20%E6%90%AD%E5%BB%BA%20ubuntu%20%E7%8E%AF%E5%A2%83.html\n拉取基本镜像 # docker pull ubuntu docker run -i -t --name mineos ubuntu bash 安装vim # apt update apt install vim 切换用户 # 添加用户\nadduser jiaqili usermod -a -G sudo jiaqili Ubuntu环境配置\n安装bazel # sudo apt install -y apt-transport-https curl gnupg BAZEL_VERSION=4.1.0 \\ \u0026amp;\u0026amp; curl https://storage.googleapis.com/bazel-apt/doc/apt-key.pub.gpg | sudo apt-key add - \\ \u0026amp;\u0026amp; echo \u0026#34;deb [arch=amd64] https://storage.googleapis.com/bazel-apt stable jdk1.8\u0026#34; | sudo tee /etc/apt/sources.list.d/bazel.list \\ \u0026amp;\u0026amp; sudo apt-get update \\ \u0026amp;\u0026amp; sudo apt-get install -y bazel-${BAZEL_VERSION} \\ \u0026amp;\u0026amp; sudo ln -s /usr/bin/bazel-${BAZEL_VERSION} /usr/bin/bazel 配置ssh # Host code.deeproute.ai User git Port 2222 StrictHostKeyChecking no PreferredAuthentications publickey IdentityFile ~/.ssh/id_rsa 安装python # 组里环境用的是3.8版本\nsudo apt install python3.8 sudo apt install python3-pip sudo apt install python 安装各种工具 # sudo apt install iputils-ping net-tools 中文支持，ubuntu镜像不带中文，ros镜像可以 # sudo apt install locales -y 跟着这个帖子操作解决了：\nhttps://zhuanlan.zhihu.com/p/76608268\n参考：\nhttps://cloud.tencent.com/developer/article/1920078\n配置 SSH # 这一步主要是为了mac 可以 ssh 连接 ubuntu 容器^[Docker-SSH连接docker容器]。\n安装 openssh-server # apt-get install openssh-server 用于开启 ssh 服务供外部连接。\n配置 sshd # 需要更改一下 sshd 的默认配置，编辑文件 /etc/ssh/sshd_config ，大概从 29 行开始主要更改三处，更改后内容如下：\nPermitRootLogin yes # 可以登录 root 用户 PubkeyAuthentication yes # 可以使用 ssh 公钥许可 AuthorizedKeysFile\t.ssh/authorized_keys # 公钥信息保存到文件 .ssh/authorized_keys 中 重启 sshd # 因为 ubuntu 过于精简，不能使用 service 命令方便的重启 sshd，这里使用命令 /etc/init.d/ssh restart 进行重启^[Ubuntu下\u0026quot;sshd:unrecognized service”]，重启是为了让上面的配置生效。\n添加主机的 ssh 公钥 # 这里的主机指的就是 macOS，保证此时还是在 ubuntu 容器中。\n在 HOME 目录下创建 .ssh 目录：mkdir ~/.ssh 新建文件 ~/.ssh/authorized_keys ：touch ~/.ssh/authorized_keys 新开一个 macOS 下的终端窗口，执行命令 cat ~/.ssh/id_rsa.pub，复制打印的一行公钥信息 回到 ubuntu 容器中，将第 3 步复制的公钥粘贴到 ~/.ssh/authorized_keys 中保存。 如果使用过ssh免密码的登陆操作的话，相信您知道ssh的密钥生成方法，如果没了解过，可以参考：ssh-keys\n此时完成了 SSH 访问支持的添加，ctrl + d 退出容器。 免密不成功，可能是文件权限问题 # :::color4 Dec 26 12:30:38 server sshd[3503454]: Authentication refused: bad ownership or modes for directory /home/user/.ssh\n:::\nAs you can see – bad ownership or modes for directory /home/user/.ssh.\nSSH doesn’t like it if your home or ~/.ssh directories have group write permissions. Your home directory should be writable only by you, ~/.ssh should be 700, and authorized_keys should be 600 :\nchmod go-w /home/user chmod 700 /home/user/.ssh chmod 600 /home/user/.ssh/authorized_keys 跳板机配置 # https://zhuanlan.zhihu.com/p/74193910\nHost onboard HostName 10.96.96.130 User onboard Port 2222 Host nvidia HostName 192.168.8.107 Port 22 User nvidia ProxyJump onboard 提交修改到镜像 # 现在已经推出到正常的 mac 终端窗口中了，容器的修改不会影响到源镜像，上面的操作我们已经完成了 Ubuntu 的基本配置，并且添加了 SSH 支持，这一步是产生新的镜像版本。\n查看刚刚操作的容器信息，执行命令 docker ps -a ，可以看到 mineos 的状态已经是退出了，主要关注 mineos 的 CONTAINER ID ，复制这个 ID 号，比如为 e5d8c1030724 执行下面的命令提交产生 ubuntu 新版本的镜像： docker commit -m \u0026#39;add ssh\u0026#39; -a \u0026#39;5km\u0026#39; e5d8c1030724 ubuntu-ssh - -m，指定提交信息 - -a，指定提交者 - 你需要把 e5d8c1030724 替换为您的容器的 CONTAINER ID - ubuntu-ssh 是新镜像的名称，可以随意指定 使用命令 docker image ls 可以查看当前安装的镜像，上述操作正常的话就会看到 ubuntu-ssh 的镜像信息 此时之前创建的容器就没用了，可以通过命令 docker rm mineos 进行删除 最终的 ubuntu 容器 # 有了具有 SSH 支持的 ubuntu 镜像，我们就可以创建新的 ubuntu 容器，通过以下命令进行创建：\ndocker run -d -p 26122:22 --name learn ubuntu-ssh /usr/sbin/sshd -D 参数 值 含义 -d 无 后台运行 -p 26122:22 绑定主机的 26122 端口到ubuntu容器的 22 端口(ssh服务的默认端口为 22) –name learn 指定容器名称为 learn ubuntu-ssh 无 使用镜像 ubuntu-ssh 创建容器 /usr/sbin/sshd -D 无 指定容器启动使用的应用及参数 在 macOS 的终端中执行命令 ssh -p 26122 root@localhost 即可连接已经启动的 ubuntu 容器 learn\n为了更方便的连接，可以为容器创建 ssh 连接的主机短名，往 macOS 的 ~/.ssh/config 中添加以下内容：\nHost learn HostName localhost User root Port 26122 此时就可以通过命令 ssh learn 连接 ubuntu 容器 learn 了。\n开发环境 # 安装各种缺失的库和工具\nsudo apt install libacl1-dev libgoogle-glog-dev libgtest-dev -y sudo apt install libncurses-dev sudo apt update \u0026amp;\u0026amp; sudo apt install deeproute-cmake-dev=3.17.0 \\ deeproute-protobuf-dev=3.13.0 \\ deeproute-os-interface-dev \\ deeproute-absl-dev=1.3.1 \\ deeproute-s2geometry-dev \\ deeproute-grpc-dev=1.37.2 安装ros # https://wiki.ros.org/melodic/Installation/Ubuntu\n遇到冲突，先装一下aptitude\nsudo apt install aptitude {% endraw %}\n"},{"id":29,"href":"/posts/1/01/%E7%B3%BB%E7%BB%9F%E6%80%A7%E8%83%BD%E7%9B%91%E6%8E%A7/","title":"系统性能监控","section":"Blog","content":" 常见工具 # collectd # perfetto # Prometheus # Grafana # 功能 # 数据采集 数据分析 数据可视化 告警 "}]